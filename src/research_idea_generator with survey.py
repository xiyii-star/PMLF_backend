"""
ç§‘ç ”å‡è®¾ç”Ÿæˆå™¨
ä½¿ç”¨æ€ç»´é“¾ï¼ˆChain of Thoughtï¼‰æ¨ç†æ¥ç”Ÿæˆå¯è¡Œçš„ç ”ç©¶åˆ›æ„
"""

import json
import logging
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
from enum import Enum
import networkx as nx

try:
    from langchain_openai import ChatOpenAI
    try:
        # å°è¯•æ–°ç‰ˆ langchain ç»“æ„ (v0.1.0+)
        from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate
        from langchain_core.output_parsers import PydanticOutputParser
    except ImportError:
        # å›é€€åˆ°æ—§ç‰ˆ langchain ç»“æ„
        from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate
        from langchain.output_parsers import PydanticOutputParser
    from pydantic import BaseModel, Field
except ImportError as e:
    raise ImportError(
        "ç¼ºå°‘å¿…éœ€çš„åŒ…ã€‚è¯·è¿è¡Œ: pip install langchain langchain-openai langchain-core pydantic"
    ) from e

# æ—¥å¿—è®°å½•å™¨
logger = logging.getLogger(__name__)


class IdeaStatus(str, Enum):
    """ç”Ÿæˆåˆ›æ„çš„çŠ¶æ€"""
    SUCCESS = "SUCCESS"  # æˆåŠŸï¼šæ–¹æ³•ä¸é™åˆ¶å…¼å®¹
    INCOMPATIBLE = "INCOMPATIBLE"  # ä¸å…¼å®¹ï¼šæ–¹æ³•æ— æ³•è§£å†³è¯¥é™åˆ¶


class InnovationIdea(BaseModel):
    """ç”Ÿæˆçš„ç ”ç©¶åˆ›æ„çš„ç»“æ„åŒ–è¾“å‡º"""
    status: IdeaStatus = Field(description="æ–¹æ³•æ˜¯å¦ä¸é™åˆ¶å…¼å®¹")
    title: Optional[str] = Field(default=None, description="å¸å¼•äººçš„å­¦æœ¯æ ‡é¢˜")
    abstract: Optional[str] = Field(
        default=None,
        description="æ ‡å‡†å­¦æœ¯æ‘˜è¦ï¼ˆèƒŒæ™¯ â†’ å·®è· â†’ æå‡ºçš„æ–¹æ³• â†’ é¢„æœŸç»“æœï¼‰"
    )
    modification: Optional[str] = Field(
        default=None,
        description="æ‰€éœ€çš„å…·ä½“ä¿®æ”¹ï¼ˆå³'æ¡¥æ¥å˜é‡'ï¼‰"
    )
    reasoning: Optional[str] = Field(
        default=None,
        description="å±•ç¤ºåˆ†æè¿‡ç¨‹çš„æ€ç»´é“¾æ¨ç†"
    )
    rationale: Optional[str] = Field(
        default=None,
        description="å®Œæ•´çš„æ¨æ¼”è·¯å¾„ï¼ŒåŒ…æ‹¬Step 1-3çš„è¯¦ç»†åˆ†æè¿‡ç¨‹ã€æ¨ç†é“¾æ¡å’Œå†³ç­–ä¾æ®"
    )


@dataclass
class IdeaFragment:
    """ç ”ç©¶ç‰‡æ®µï¼ˆé™åˆ¶æˆ–æ–¹æ³•ï¼‰"""
    content: str  # ç‰‡æ®µå†…å®¹
    paper_id: str = ""  # è®ºæ–‡ID
    paper_title: str = ""  # è®ºæ–‡æ ‡é¢˜
    year: int = 0  # å‘è¡¨å¹´ä»½
    cited_count: int = 0  # è¢«å¼•ç”¨æ¬¡æ•°


class HypothesisGenerator:
    """
    å‡è®¾ç”Ÿæˆå™¨ï¼Œä½¿ç”¨æ€ç»´é“¾ï¼ˆChain of Thoughtï¼‰æ¨ç†

    å¤„ç†æµç¨‹:
    1. åˆ†æå…¼å®¹æ€§ï¼šæ£€æŸ¥æ•°å­¦/ç†è®ºå…¼å®¹æ€§
    2. è¯†åˆ«å·®è·ï¼šç¡®å®šéœ€è¦ä»€ä¹ˆä¿®æ”¹
    3. èµ·è‰åˆ›æ„ï¼šç”Ÿæˆç»“æ„åŒ–çš„ç ”ç©¶ææ¡ˆ
    """

    def __init__(
        self,
        model_name: str = "gpt-4o",
        temperature: float = 0.3,
        api_key: Optional[str] = None,
        base_url: Optional[str] = None
    ):
        """
        åˆå§‹åŒ–å‡è®¾ç”Ÿæˆå™¨

        Args:
            model_name: OpenAI æ¨¡å‹åç§°ï¼ˆä¾‹å¦‚ï¼š"gpt-4", "gpt-3.5-turbo"ï¼‰
            temperature: é‡‡æ ·æ¸©åº¦ï¼ˆè¶Šä½è¶Šèšç„¦ï¼Œè¶Šé«˜è¶Šæœ‰åˆ›é€ æ€§ï¼‰
            api_key: OpenAI API å¯†é’¥ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨ OPENAI_API_KEY ç¯å¢ƒå˜é‡ï¼‰
            base_url: APIçš„å¯é€‰åŸºç¡€URLï¼ˆç”¨äºä»£ç†æˆ–è‡ªå®šä¹‰ç«¯ç‚¹ï¼‰
        """
        # æ„å»º LLM å‚æ•°
        llm_kwargs = {
            "model": model_name,
            "temperature": temperature,
        }

        if api_key:
            llm_kwargs["api_key"] = api_key
        if base_url:
            llm_kwargs["base_url"] = base_url

        # åˆå§‹åŒ– OpenAI LLM å®¢æˆ·ç«¯
        self.llm = ChatOpenAI(**llm_kwargs)
        # åˆå§‹åŒ–è¾“å‡ºè§£æå™¨ï¼Œç”¨äºè§£æç»“æ„åŒ–è¾“å‡º
        self.output_parser = PydanticOutputParser(pydantic_object=InnovationIdea)

        # æ„å»ºæç¤ºè¯æ¨¡æ¿
        self.prompt_template = self._build_prompt_template()

        logger.info(f"å‡è®¾ç”Ÿæˆå™¨å·²ä½¿ç”¨æ¨¡å‹åˆå§‹åŒ–: {model_name}")

    def _format_evolutionary_context(self, evolutionary_paths: Optional[List[Dict]] = None) -> str:
        """
        æ ¼å¼åŒ–æ¼”åŒ–è·¯å¾„ä¸ºæç¤ºè¯ä¸Šä¸‹æ–‡
        
        Args:
            evolutionary_paths: æ¼”åŒ–è·¯å¾„åˆ—è¡¨ï¼Œæ¯ä¸ªè·¯å¾„åŒ…å«ï¼š
                - thread_type: 'chain', 'divergence', 'convergence'
                - pattern_type: æ¨¡å¼æè¿°
                - title: æ ‡é¢˜
                - narrative: å™äº‹æ–‡æœ¬
                - papers: è®ºæ–‡ä¿¡æ¯åˆ—è¡¨
                - relation_chain: å…³ç³»é“¾ï¼ˆåŒ…å« Overcomes, Extends, Realizes ç­‰ï¼‰
                - routes: å¯¹äºåˆ†åŒ–/æ±‡èšæ¨¡å¼ï¼ŒåŒ…å«å¤šæ¡è·¯çº¿
        
        Returns:
            æ ¼å¼åŒ–çš„æ¼”åŒ–ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
        """
        if not evolutionary_paths or len(evolutionary_paths) == 0:
            return ""
        
        context_parts = [
            "**EVOLUTIONARY CONTEXT (Learn from Research Evolution Patterns):**",
            "",
            "The following evolutionary paths show how research has evolved in this field. ",
            "Learn from these patterns to generate better research ideas:",
            ""
        ]
        
        for i, path in enumerate(evolutionary_paths[:3], 1):  # æœ€å¤šä½¿ç”¨å‰3æ¡è·¯å¾„
            thread_type = path.get('thread_type', 'unknown')
            pattern_type = path.get('pattern_type', 'Unknown Pattern')
            title = path.get('title', '')
            narrative = path.get('narrative', '')
            relation_chain = path.get('relation_chain', [])
            
            context_parts.append(f"**Evolutionary Path {i}: {pattern_type}**")
            context_parts.append(f"Title: {title}")
            context_parts.append(f"Narrative: {narrative[:500]}...")  # é™åˆ¶é•¿åº¦
            
            # æå–å…³é”®æ¼”åŒ–é€»è¾‘
            if relation_chain:
                context_parts.append("Key Evolution Logic:")
                for rel in relation_chain[:3]:  # æœ€å¤šæ˜¾ç¤º3ä¸ªå…³ç³»
                    from_paper = rel.get('from_paper', {}).get('title', 'Unknown')
                    to_paper = rel.get('to_paper', {}).get('title', 'Unknown')
                    relation_type = rel.get('relation_type', 'Unknown')
                    narrative_rel = rel.get('narrative_relation', relation_type)
                    
                    context_parts.append(
                        f"  - {from_paper[:60]}... "
                        f"--[{narrative_rel}]--> "
                        f"{to_paper[:60]}..."
                    )
            
            # å¯¹äºåˆ†åŒ–/æ±‡èšæ¨¡å¼ï¼Œæå–è·¯çº¿ä¿¡æ¯
            if thread_type in ['divergence', 'convergence']:
                routes = path.get('routes', [])
                if routes:
                    context_parts.append(f"Routes ({len(routes)} branches):")
                    for route_idx, route in enumerate(routes[:2], 1):  # æœ€å¤šæ˜¾ç¤º2æ¡è·¯çº¿
                        route_papers = route.get('papers', [])
                        if route_papers:
                            first_paper = route_papers[0].get('title', 'Unknown')[:50]
                            context_parts.append(f"  Route {route_idx}: {first_paper}...")
            
            context_parts.append("")
        
        context_parts.append(
            "**Learning Instructions:** "
            "Analyze how limitations were overcome, how methods were extended, "
            "and how cross-domain adaptations worked. Apply similar logic to generate your idea."
        )
        
        return "\n".join(context_parts)

    def _build_prompt_template(self) -> ChatPromptTemplate:
        """æ„å»ºæ€ç»´é“¾æç¤ºè¯æ¨¡æ¿ï¼ˆæ”¯æŒæ¼”åŒ–è·¯å¾„ä¸Šä¸‹æ–‡ï¼‰"""

        system_message = SystemMessagePromptTemplate.from_template(
            """You are a **Senior Principal Researcher** with deep expertise in analyzing research problems and generating innovative solutions.

Your task is to evaluate whether a candidate method can solve a given research limitation, following a rigorous Chain of Thought reasoning process.

**Your reasoning must follow these three steps:**

**Step 1: Analyze Compatibility**
- Examine the mathematical, algorithmic, and theoretical properties of the method
- Check if these properties align with the constraints and requirements of the limitation
- Consider: computational complexity, applicability domain, underlying assumptions
- If fundamentally incompatible, output status="INCOMPATIBLE" and stop

**Step 2: Identify the Gap**
- Determine what specific modifications are needed to bridge the gap
- Identify the "Bridging Variable" - the key innovation that makes the connection work
- Ask: What needs to change in the method to address this new problem context?

**Step 3: Draft the Idea**
- Create a catchy, academic title
- Write a structured abstract following: Background â†’ Gap â†’ Proposed Method â†’ Expected Result
- Clearly state the core innovation in one sentence

**Rationale (Complete Reasoning Path):**
You must provide a comprehensive rationale that documents the complete reasoning path, including:
- **Step 1 Analysis**: Detailed compatibility analysis with specific technical considerations
- **Step 2 Analysis**: Detailed gap identification with the bridging variable explanation
- **Step 3 Analysis**: Detailed idea drafting process and innovation justification
- **Decision Chain**: The logical chain of reasoning from limitation â†’ method compatibility â†’ gap â†’ solution
- **Evidence**: Key evidence or patterns from evolutionary paths (if provided) that support the reasoning

The rationale should be a complete, structured narrative that allows readers to understand the full reasoning process behind the generated idea.

**Evolutionary Context (if provided):**
When evolutionary paths are provided, you should:
- Learn from the evolution patterns (Chain, Divergence, Convergence)
- Understand how previous research has evolved: what limitations were overcome, what methods were extended
- Apply similar evolutionary logic: if Method A overcame Limitation X, and Method B extends Method A, consider how Method B might address similar limitations
- Identify patterns: successful combinations, common adaptation strategies, cross-domain transfers

{format_instructions}

Be rigorous and honest. If something won't work, say INCOMPATIBLE. Only output SUCCESS for truly feasible ideas."""
        )

        human_message = HumanMessagePromptTemplate.from_template(
            """**LIMITATION (Current Research Bottleneck):**
{limitation}

**CANDIDATE METHOD (Potential Solution):**
{method}

{evolutionary_context}

Now, follow the three-step Chain of Thought process:

1. **Compatibility Analysis**: Are the mathematical/algorithmic properties of this method suitable for the limitation's constraints?

2. **Gap Identification**: What specific modification or adaptation is needed? Consider evolutionary patterns if provided.

3. **Idea Drafting**: If feasible, create the title, abstract, and describe the core innovation. Learn from how similar problems were solved in the evolutionary paths.

**Important**: You must provide a comprehensive "rationale" field that documents the complete reasoning path, including detailed analysis for each step, the decision chain, and supporting evidence. This rationale should be a complete narrative that explains the full thought process.

Provide your complete reasoning and final output in the specified JSON format."""
        )

        return ChatPromptTemplate.from_messages([system_message, human_message])

    def generate_innovation_idea(
        self,
        limitation: str,
        method: str,
        evolutionary_paths: Optional[List[Dict]] = None,
        verbose: bool = False
    ) -> Dict:
        """
        ä»é™åˆ¶å’Œå€™é€‰æ–¹æ³•ç”Ÿæˆç ”ç©¶åˆ›æ–°åˆ›æ„

        Args:
            limitation: ç ”ç©¶ç“¶é¢ˆ/é™åˆ¶çš„æè¿°
            method: å€™é€‰æ–¹æ³•çš„æè¿°
            evolutionary_paths: å¯é€‰çš„æ¼”åŒ–è·¯å¾„åˆ—è¡¨ï¼Œç”¨äºæä¾›ä¸Šä¸‹æ–‡å’Œå­¦ä¹ æ¼”åŒ–é€»è¾‘
            verbose: å¦‚æœä¸ºTrueï¼Œæ‰“å°è¯¦ç»†çš„æ¨ç†è¿‡ç¨‹

        Returns:
            åŒ…å«ä»¥ä¸‹ç»“æ„çš„å­—å…¸:
            {
                "status": "SUCCESS" æˆ– "INCOMPATIBLE",
                "title": "...",
                "abstract": "...",
                "modification": "...",
                "reasoning": "...",
                "rationale": "..."  # å®Œæ•´çš„æ¨æ¼”è·¯å¾„ï¼ŒåŒ…æ‹¬Step 1-3çš„è¯¦ç»†åˆ†æ
            }
        """
        try:
            # æ ¼å¼åŒ–æ¼”åŒ–ä¸Šä¸‹æ–‡
            evolutionary_context = self._format_evolutionary_context(evolutionary_paths)
            
            # æ ¼å¼åŒ–æç¤ºè¯
            formatted_prompt = self.prompt_template.format_messages(
                limitation=limitation,
                method=method,
                evolutionary_context=evolutionary_context,
                format_instructions=self.output_parser.get_format_instructions()
            )

            if verbose:
                logger.info("=" * 80)
                logger.info("æ­£åœ¨ç”Ÿæˆåˆ›æ–°åˆ›æ„...")
                logger.info(f"é™åˆ¶: {limitation[:100]}...")
                logger.info(f"æ–¹æ³•: {method[:100]}...")

            # è°ƒç”¨ LLM
            response = self.llm.invoke(formatted_prompt)

            # è§£æç»“æ„åŒ–è¾“å‡º
            idea = self.output_parser.parse(response.content)

            if verbose:
                logger.info(f"çŠ¶æ€: {idea.status}")
                if idea.status == IdeaStatus.SUCCESS:
                    logger.info(f"æ ‡é¢˜: {idea.title}")
                    logger.info(f"ä¿®æ”¹: {idea.modification}")
                    if idea.rationale:
                        logger.info(f"æ¨æ¼”è·¯å¾„é•¿åº¦: {len(idea.rationale)} å­—ç¬¦")
                logger.info("=" * 80)

            # è½¬æ¢ä¸ºå­—å…¸
            result = {
                "status": idea.status,
                "title": idea.title,
                "abstract": idea.abstract,
                "modification": idea.modification,
                "reasoning": idea.reasoning,
                "rationale": idea.rationale  # å®Œæ•´çš„æ¨æ¼”è·¯å¾„
            }

            return result

        except Exception as e:
            logger.error(f"ç”Ÿæˆåˆ›æ–°åˆ›æ„æ—¶å‡ºé”™: {e}")
            return {
                "status": "ERROR",
                "title": None,
                "abstract": None,
                "modification": None,
                "reasoning": f"ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}",
                "rationale": None
            }

    def batch_generate(
        self,
        unsolved_limitations: List[str],
        candidate_methods: List[str],
        evolutionary_paths: Optional[List[Dict]] = None,
        max_ideas: int = 10,
        verbose: bool = False
    ) -> List[Dict]:
        """
        é€šè¿‡å°†é™åˆ¶ä¸æ–¹æ³•é…å¯¹æ¥ç”Ÿæˆå¤šä¸ªåˆ›æ„

        Args:
            unsolved_limitations: é™åˆ¶æè¿°åˆ—è¡¨
            candidate_methods: æ–¹æ³•æè¿°åˆ—è¡¨
            evolutionary_paths: å¯é€‰çš„æ¼”åŒ–è·¯å¾„åˆ—è¡¨ï¼Œç”¨äºæä¾›ä¸Šä¸‹æ–‡å’Œå­¦ä¹ æ¼”åŒ–é€»è¾‘
            max_ideas: è¦ç”Ÿæˆçš„æœ€å¤§åˆ›æ„æ•°é‡
            verbose: å¦‚æœä¸ºTrueï¼Œæ‰“å°è¿›åº¦

        Returns:
            ç”Ÿæˆçš„åˆ›æ„åˆ—è¡¨ï¼ˆä»…æˆåŠŸçš„åˆ›æ„ï¼‰
        """
        ideas = []
        count = 0

        for limitation in unsolved_limitations:
            if count >= max_ideas:
                break

            for method in candidate_methods:
                if count >= max_ideas:
                    break

                if verbose:
                    logger.info(f"\næ­£åœ¨ç”Ÿæˆåˆ›æ„ {count + 1}/{max_ideas}...")

                idea = self.generate_innovation_idea(
                    limitation, 
                    method, 
                    evolutionary_paths=evolutionary_paths,
                    verbose=False
                )

                # ä»…ä¿ç•™æˆåŠŸçš„åˆ›æ„
                if idea["status"] == "SUCCESS":
                    ideas.append({
                        "limitation": limitation,
                        "method": method,
                        **idea
                    })
                    count += 1

                    if verbose:
                        logger.info(f"âœ“ æˆåŠŸ: {idea['title']}")
                else:
                    if verbose:
                        logger.info(f"âœ— ä¸å…¼å®¹: æ–¹æ³•ä¸åˆé€‚")

        return ideas


class KnowledgeGraphExtractor:
    """
    çŸ¥è¯†å›¾è°±æ•°æ®æå–å™¨

    ä»åŒ…å«è®ºæ–‡ä¿¡æ¯çš„çŸ¥è¯†å›¾è°±ä¸­æå–ç ”ç©¶å±€é™æ€§(Limitations)å’Œå€™é€‰æ–¹æ³•(Methods)ã€‚
    è¿™äº›æå–çš„å†…å®¹å°†ç”¨äºç ”ç©¶åˆ›æ„ç”Ÿæˆ,é€šè¿‡å°†æœªè§£å†³çš„å±€é™æ€§ä¸å€™é€‰æ–¹æ³•è¿›è¡Œç»„åˆæ¥äº§ç”Ÿæ–°çš„ç ”ç©¶æ–¹å‘ã€‚

    å·¥ä½œåŸç†:
        1. éå†çŸ¥è¯†å›¾è°±ä¸­çš„æ‰€æœ‰èŠ‚ç‚¹
        2. ä»èŠ‚ç‚¹å±æ€§ä¸­æå– limitations (ç ”ç©¶ç“¶é¢ˆ/éœ€è¦è§£å†³çš„é—®é¢˜)
        3. ä»èŠ‚ç‚¹å±æ€§ä¸­æå– methods (æ½œåœ¨çš„è§£å†³æ–¹æ¡ˆ/è´¡çŒ®)
        4. å¯¹æå–çš„å†…å®¹è¿›è¡Œè¿‡æ»¤å’Œå»é‡

    ä½¿ç”¨åœºæ™¯:
        - åœ¨ç”Ÿæˆç ”ç©¶åˆ›æ„ä¹‹å‰,ä»å·²æ„å»ºçš„æ–‡çŒ®çŸ¥è¯†å›¾è°±ä¸­æå–åŸææ–™
        - ä¸º HypothesisGenerator å‡†å¤‡è¾“å…¥æ•°æ®
    """

    @staticmethod
    def extract_from_graph(
        graph: nx.Graph,
        min_text_length: int = 50
    ) -> tuple[List[str], List[str]]:
        """
        ä» NetworkX çŸ¥è¯†å›¾è°±ä¸­æå–å±€é™æ€§å’Œæ–¹æ³•ï¼ˆåŸºäºå¼•ç”¨å…³ç³»ç±»å‹çš„ç¢ç‰‡æ± åŒ–ï¼‰

        ğŸ”Œ ç¢ç‰‡æ± åŒ–ç­–ç•¥ (Fragment Pooling)ï¼š
        é€šè¿‡åˆ†æå¼•ç”¨å…³ç³»ç±»å‹ï¼ˆSocket Matching çš„ç»“æœï¼‰ï¼Œæ™ºèƒ½ç­›é€‰é«˜è´¨é‡çš„ç ”ç©¶ç¢ç‰‡ã€‚

        ğŸ“¦ å››å¤§ç¢ç‰‡æ± ï¼š
        - Pool A (Unsolved Limitations): æœªè¢« Overcomes çš„ Limitation
          â†’ è¿™äº›æ˜¯å°šæœªè§£å†³çš„ç ”ç©¶ç“¶é¢ˆï¼Œæœ€å€¼å¾—æ”»å…‹
        - Pool B (Successful Methods): è¢« Extends å¤šæ¬¡çš„ Method
          â†’ è¿™äº›æ–¹æ³•è¢«å¤šæ¬¡æ‰©å±•ï¼Œè¯æ˜æ˜¯æˆç†Ÿå¯é çš„åŸºç¡€æŠ€æœ¯
        - Pool C (Cross-Domain Methods): æ¥è‡ª Adapts_to æºå¤´çš„ Method
          â†’ è¿™äº›æ–¹æ³•å·²è¯æ˜å…·æœ‰è·¨é¢†åŸŸè¿ç§»èƒ½åŠ›ï¼Œé€‚åˆæ–°åœºæ™¯
        - Pool D (Unrealized Future Work): æœªè¢« Realizes çš„ Future Work
          â†’ è¿™äº›æ˜¯å‰äººè®¾æƒ³ä½†å°šæœªå®ç°çš„ç ”ç©¶æ–¹å‘

        ğŸ”— Limitation æ¥æºï¼šPool A + Pool D
        ğŸ”§ Method æ¥æºï¼šPool B + Pool C

        Args:
            graph: NetworkX å›¾å¯¹è±¡ï¼ŒèŠ‚ç‚¹åŒ…å«è®ºæ–‡ä¿¡æ¯ï¼Œè¾¹åŒ…å«å¼•ç”¨å…³ç³»ç±»å‹
                   é¢„æœŸçš„èŠ‚ç‚¹å±æ€§:
                   - rag_limitation (str): RAG æå–çš„å±€é™æ€§
                   - rag_future_work (str): RAG æå–çš„æœªæ¥å·¥ä½œ
                   - rag_method (str): RAG æå–çš„è´¡çŒ®/æ–¹æ³•
                   é¢„æœŸçš„è¾¹å±æ€§:
                   - edge_type (str): å¼•ç”¨å…³ç³»ç±»å‹ (Overcomes, Realizes, Extends, etc.)
            min_text_length: æœ‰æ•ˆæ–‡æœ¬çš„æœ€å°é•¿åº¦ï¼Œé»˜è®¤ 50 å­—ç¬¦

        Returns:
            tuple[List[str], List[str]]:
                - unsolved_limitations: é«˜è´¨é‡çš„æœªè§£å†³å±€é™æ€§åˆ—è¡¨ï¼ˆPool A + Pool Dï¼‰
                - candidate_methods: é«˜è´¨é‡çš„å€™é€‰æ–¹æ³•åˆ—è¡¨ï¼ˆPool B + Pool Cï¼‰

        Example:
            >>> G = nx.Graph()
            >>> G.add_node('W1', rag_limitation='High complexity', rag_method='Method A')
            >>> G.add_node('W2', rag_method='Method B')
            >>> G.add_edge('W2', 'W1', edge_type='Extends')
            >>> limitations, methods = KnowledgeGraphExtractor.extract_from_graph(G)
        """
        logger.info("ğŸ”Œ å¼€å§‹ç¢ç‰‡æ± åŒ–æå– (Fragment Pooling based on Socket Matching)")

        # ===== ç»Ÿè®¡è¾¹ç±»å‹ä¿¡æ¯ =====
        # ç»Ÿè®¡æ¯ä¸ªèŠ‚ç‚¹è¢«å“ªäº›ç±»å‹çš„è¾¹æŒ‡å‘ï¼Œä»¥åŠæŒ‡å‘å“ªäº›èŠ‚ç‚¹
        node_incoming_edges = {}  # èŠ‚ç‚¹è¢«å“ªäº›è¾¹æŒ‡å‘ {node_id: [(source, edge_type), ...]}
        node_outgoing_edges = {}  # èŠ‚ç‚¹æŒ‡å‘å“ªäº›è¾¹ {node_id: [(target, edge_type), ...]}

        for source, target, edge_data in graph.edges(data=True):
            edge_type = edge_data.get('edge_type', 'Unknown')

            # è®°å½• target è¢« source é€šè¿‡ edge_type å¼•ç”¨
            if target not in node_incoming_edges:
                node_incoming_edges[target] = []
            node_incoming_edges[target].append((source, edge_type))

            # è®°å½• source é€šè¿‡ edge_type å¼•ç”¨äº† target
            if source not in node_outgoing_edges:
                node_outgoing_edges[source] = []
            node_outgoing_edges[source].append((target, edge_type))

        # ===== Pool A: Unsolved Limitations (æœªè¢« Overcomes çš„ Limitation) =====
        pool_a_limitations = []

        for node_id, node_data in graph.nodes(data=True):
            # æå– limitation
            limitation_text = node_data.get('rag_limitation', '')
            if not isinstance(limitation_text, str) or len(limitation_text.strip()) <= min_text_length:
                continue

            # æ£€æŸ¥æ˜¯å¦è¢« Overcomes
            incoming_edges = node_incoming_edges.get(node_id, [])
            is_overcome = any(edge_type == 'Overcomes' for _, edge_type in incoming_edges)

            if not is_overcome:
                # æœªè¢«è§£å†³çš„ limitation
                pool_a_limitations.append(limitation_text.strip())

        logger.info(f"ğŸ“¦ Pool A (Unsolved Limitations): {len(pool_a_limitations)} æ¡")

        # ===== Pool D: Unrealized Future Work (æœªè¢« Realizes çš„ Future Work) =====
        pool_d_limitations = []

        for node_id, node_data in graph.nodes(data=True):
            # æå– future_work
            future_work_text = node_data.get('rag_future_work', '')
            if not isinstance(future_work_text, str) or len(future_work_text.strip()) <= min_text_length:
                continue

            # æ£€æŸ¥æ˜¯å¦è¢« Realizes
            incoming_edges = node_incoming_edges.get(node_id, [])
            is_realized = any(edge_type == 'Realizes' for _, edge_type in incoming_edges)

            if not is_realized:
                # æœªå®ç°çš„ future work
                pool_d_limitations.append(future_work_text.strip())

        logger.info(f"ğŸ“¦ Pool D (Unrealized Future Work): {len(pool_d_limitations)} æ¡")

        # ===== Pool B: Successful Methods (è¢« Extends å¤šæ¬¡çš„ Method) =====
        pool_b_methods = []
        extends_threshold = 2  # è‡³å°‘è¢« Extends 2 æ¬¡æ‰ç®—æˆç†Ÿæ–¹æ³•

        for node_id, node_data in graph.nodes(data=True):
            # æå– contribution (method)
            contribution_text = node_data.get('rag_method', '')
            if not isinstance(contribution_text, str) or len(contribution_text.strip()) <= min_text_length:
                continue

            # ç»Ÿè®¡è¢« Extends çš„æ¬¡æ•°
            incoming_edges = node_incoming_edges.get(node_id, [])
            extends_count = sum(1 for _, edge_type in incoming_edges if edge_type == 'Extends')

            if extends_count >= extends_threshold:
                # è¢«å¤šæ¬¡æ‰©å±•çš„æˆç†Ÿæ–¹æ³•
                pool_b_methods.append(contribution_text.strip())

        logger.info(f"ğŸ“¦ Pool B (Successful Methods, Extendsâ‰¥{extends_threshold}): {len(pool_b_methods)} æ¡")

        # ===== Pool C: Cross-Domain Methods (æ¥è‡ª Adapts_to æºå¤´çš„ Method) =====
        pool_c_methods = []

        # æ‰¾å‡ºæ‰€æœ‰ Adapts_to è¾¹çš„æºèŠ‚ç‚¹
        adapts_to_sources = set()
        for source, target, edge_data in graph.edges(data=True):
            if edge_data.get('edge_type') == 'Adapts_to':
                adapts_to_sources.add(target)  # target æ˜¯è¢«è¿ç§»çš„æºè®ºæ–‡

        # æå–è¿™äº›æºèŠ‚ç‚¹çš„ method
        for node_id in adapts_to_sources:
            node_data = graph.nodes[node_id]
            contribution_text = node_data.get('rag_method', '')
            if isinstance(contribution_text, str) and len(contribution_text.strip()) > min_text_length:
                pool_c_methods.append(contribution_text.strip())

        logger.info(f"ğŸ“¦ Pool C (Cross-Domain Methods from Adapts_to): {len(pool_c_methods)} æ¡")

        # ===== åˆå¹¶æ± åŒ–ç»“æœ =====
        # Limitations = Pool A + Pool D
        unsolved_limitations = pool_a_limitations + pool_d_limitations
        # Methods = Pool B + Pool C
        candidate_methods = pool_b_methods + pool_c_methods

        # å»é‡
        unsolved_limitations = list(set(unsolved_limitations))
        candidate_methods = list(set(candidate_methods))

        # ===== é™çº§ç­–ç•¥ï¼šå¦‚æœç¢ç‰‡æ± åŒ–ç»“æœä¸è¶³ï¼Œè¡¥å……ä¼ ç»Ÿæ–¹æ³• =====
        if len(unsolved_limitations) < 3 or len(candidate_methods) < 3:
            logger.warning("âš ï¸ ç¢ç‰‡æ± åŒ–ç»“æœä¸è¶³ï¼Œå¯ç”¨é™çº§ç­–ç•¥ï¼ˆè¡¥å……ä¼ ç»Ÿæå–ï¼‰")
            fallback_limitations, fallback_methods = KnowledgeGraphExtractor._fallback_extract(
                graph, min_text_length
            )

            # è¡¥å……åˆ°ç°æœ‰æ± ä¸­
            unsolved_limitations.extend(fallback_limitations)
            candidate_methods.extend(fallback_methods)

            # å†æ¬¡å»é‡
            unsolved_limitations = list(set(unsolved_limitations))
            candidate_methods = list(set(candidate_methods))

            logger.info(f"  è¡¥å……å Limitations: {len(unsolved_limitations)} æ¡")
            logger.info(f"  è¡¥å……å Methods: {len(candidate_methods)} æ¡")

        # è¾“å‡ºæœ€ç»ˆç»Ÿè®¡
        logger.info(f"\\nâœ… ç¢ç‰‡æ± åŒ–å®Œæˆ:")
        logger.info(f"  ğŸ“Š Limitations (Pool A + Pool D): {len(unsolved_limitations)} æ¡")
        logger.info(f"  ğŸ”§ Methods (Pool B + Pool C): {len(candidate_methods)} æ¡")

        return unsolved_limitations, candidate_methods

    @staticmethod
    def _fallback_extract(
        graph: nx.Graph,
        min_text_length: int = 50
    ) -> tuple[List[str], List[str]]:
        """
        é™çº§æå–ç­–ç•¥ï¼šå½“ç¢ç‰‡æ± åŒ–ç»“æœä¸è¶³æ—¶ï¼Œä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•è¡¥å……

        ç®€å•åœ°ä»æ‰€æœ‰èŠ‚ç‚¹æå– limitation å’Œ contributionï¼Œä¸è€ƒè™‘å¼•ç”¨å…³ç³»

        Args:
            graph: NetworkX å›¾å¯¹è±¡
            min_text_length: æœ€å°æ–‡æœ¬é•¿åº¦

        Returns:
            tuple[List[str], List[str]]: (limitations, methods)
        """
        fallback_limitations = []
        fallback_methods = []

        for _, node_data in graph.nodes(data=True):
            # æå– limitation
            limitation_text = node_data.get('rag_limitation', '')
            if isinstance(limitation_text, str) and len(limitation_text.strip()) > min_text_length:
                fallback_limitations.append(limitation_text.strip())

            # æå– contribution
            contribution_text = node_data.get('rag_method', '')
            if isinstance(contribution_text, str) and len(contribution_text.strip()) > min_text_length:
                fallback_methods.append(contribution_text.strip())

        return list(set(fallback_limitations)), list(set(fallback_methods))


class ResearchIdeaGenerator:
    """
    ç ”ç©¶åˆ›æ„ç”Ÿæˆå™¨ - ä¸¤æ­¥æµç¨‹ï¼šè·å– â†’ ç”Ÿæˆ

    ğŸ“‹ æ ¸å¿ƒæµç¨‹ï¼ˆä¸¤æ­¥ï¼‰ï¼š
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Step 1: è·å– Limitation å’Œ Method                         â”‚
    â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
    â”‚  - KnowledgeGraphExtractor.extract_from_graph()           â”‚
    â”‚  - ç¢ç‰‡æ± åŒ–ï¼šåŸºäºå¼•ç”¨å…³ç³»ç±»å‹ï¼ˆSocket Matchingï¼‰           â”‚
    â”‚  - Pool A: æœªè¢« Overcomes çš„ Limitation                   â”‚
    â”‚  - Pool B: è¢« Extends â‰¥2 æ¬¡çš„ Method                      â”‚
    â”‚  - Pool C: æ¥è‡ª Adapts_to çš„ Method                       â”‚
    â”‚  - Pool D: æœªè¢« Realizes çš„ Future Work                   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Step 2: åˆ›æ„ç”Ÿæˆï¼ˆå«æ¼”åŒ–è·¯å¾„å­¦ä¹  + è‡ªåŠ¨è¿‡æ»¤ï¼‰              â”‚
    â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
    â”‚  - HypothesisGenerator.batch_generate()                   â”‚
    â”‚  - Limitation Ã— Method ç¬›å¡å°”ç§¯                            â”‚
    â”‚  - Chain of Thought æ¨ç†ï¼š                                 â”‚
    â”‚    1. Compatibility Analysisï¼ˆå…¼å®¹æ€§åˆ†æï¼‰                 â”‚
    â”‚    2. Gap Identificationï¼ˆå·®è·è¯†åˆ«ï¼‰                       â”‚
    â”‚    3. Idea Draftingï¼ˆåˆ›æ„è‰æ‹Ÿï¼‰                            â”‚
    â”‚  - æ¼”åŒ–è·¯å¾„å­¦ä¹ ï¼ˆæ–°å¢ï¼‰ï¼š                                   â”‚
    â”‚    * æ•´åˆ deep_survey_analyzer çš„æ¼”åŒ–è·¯å¾„ç»“æœ              â”‚
    â”‚    * å­¦ä¹ æ¼”åŒ–è„‰ç»œé€»è¾‘ï¼ˆChain/Divergence/Convergenceï¼‰       â”‚
    â”‚    * å­¦ä¹ å¦‚ä½•ç»„åˆ Limitation å’Œ Method                     â”‚
    â”‚    * å‚è€ƒå†å²æˆåŠŸæ¡ˆä¾‹çš„æ¼”åŒ–æ¨¡å¼                             â”‚
    â”‚  - è‡ªåŠ¨è¿‡æ»¤ï¼šåªä¿ç•™ status="SUCCESS" çš„åˆ›æ„                â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    æ¶æ„è®¾è®¡:
        ResearchIdeaGenerator (é«˜å±‚æ¥å£ - åè°ƒä¸¤æ­¥æµç¨‹)
            â”œâ”€â”€ KnowledgeGraphExtractor (Step 1: è·å–)
            â”‚   â””â”€â”€ extract_from_graph() - ç¢ç‰‡æ± åŒ–
            â””â”€â”€ HypothesisGenerator (Step 2: ç”Ÿæˆ)
                â””â”€â”€ batch_generate() - CoT æ¨ç† + è‡ªåŠ¨è¿‡æ»¤

    ä½¿ç”¨åœºæ™¯:
        - æ–‡çŒ®ç»¼è¿°åçš„åˆ›æ„ç”Ÿæˆ
        - ä»çŸ¥è¯†å›¾è°±å‘ç°ç ”ç©¶æœºä¼š
        - æ‰¹é‡ç”Ÿæˆå’Œç­›é€‰ç ”ç©¶å‡è®¾

    Example:
        >>> # åˆå§‹åŒ–ç”Ÿæˆå™¨
        >>> config = {'model_name': 'gpt-4o', 'max_ideas': 10}
        >>> generator = ResearchIdeaGenerator(config=config)
        >>>
        >>> # ä»çŸ¥è¯†å›¾è°±ç”Ÿæˆåˆ›æ„ï¼ˆä¸¤æ­¥æµç¨‹è‡ªåŠ¨æ‰§è¡Œï¼‰
        >>> result = generator.generate_from_knowledge_graph(
        ...     graph=citation_graph,
        ...     topic="Transformer Optimization"
        ... )
        >>>
        >>> # æŸ¥çœ‹ç»“æœ
        >>> print(f"Step 1: {result['pools']['unsolved_limitations']} limitations")
        >>> print(f"Step 1: {result['pools']['candidate_methods']} methods")
        >>> print(f"Step 2: {result['successful_ideas']} successful ideas")
    """

    def __init__(
        self,
        config: Dict = None,
        llm_client = None,
        critic_agent = None
    ):
        """
        åˆå§‹åŒ–ç ”ç©¶åˆ›æ„ç”Ÿæˆå™¨

        æ³¨æ„:
            - ä¸ºäº†ä¿æŒå‘åå…¼å®¹æ€§,ä¿ç•™äº† llm_client å’Œ critic_agent å‚æ•°
            - è¿™äº›å‚æ•°åœ¨å½“å‰å®ç°ä¸­è¢«å¿½ç•¥,å› ä¸ºä½¿ç”¨äº†æ–°çš„ HypothesisGenerator
            - å¦‚æœä½ æ˜¯æ–°ç”¨æˆ·,åªéœ€è¦ä¼ å…¥ config å‚æ•°å³å¯

        Args:
            config: é…ç½®å­—å…¸,æ”¯æŒä»¥ä¸‹é”®å€¼:
                - model_name (str): OpenAI æ¨¡å‹åç§°,é»˜è®¤ 'gpt-4o'
                  æ”¯æŒ: gpt-4o, gpt-4, gpt-3.5-turbo ç­‰
                - temperature (float): é‡‡æ ·æ¸©åº¦,é»˜è®¤ 0.3
                  èŒƒå›´: 0.0-1.0 (è¶Šä½è¶Šç¡®å®š,è¶Šé«˜è¶Šæœ‰åˆ›é€ æ€§)
                - openai_api_key (str): OpenAI API å¯†é’¥
                  å¦‚æœä¸æä¾›,å°†ä½¿ç”¨ç¯å¢ƒå˜é‡ OPENAI_API_KEY
                - openai_base_url (str): API åŸºç¡€ URL (å¯é€‰)
                  ç”¨äºä»£ç†æˆ–è‡ªå®šä¹‰ç«¯ç‚¹
                - max_ideas (int): æœ€å¤§ç”Ÿæˆåˆ›æ„æ•°é‡,é»˜è®¤ 10
            llm_client: (å·²åºŸå¼ƒ) æ—§ç‰ˆ LLM å®¢æˆ·ç«¯,ä¿ç•™ç”¨äºå‘åå…¼å®¹
            critic_agent: (å·²åºŸå¼ƒ) æ—§ç‰ˆè¯„åˆ¤ä»£ç†,ä¿ç•™ç”¨äºå‘åå…¼å®¹

        """
        # åŠ è½½é…ç½®,å¦‚æœæœªæä¾›åˆ™ä½¿ç”¨ç©ºå­—å…¸
        self.config = config or {}

        # ===== æå– OpenAI ç›¸å…³é…ç½® =====
        # ä» config ä¸­æå–å„é¡¹é…ç½®,å¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨é»˜è®¤å€¼
        # ä¼˜å…ˆä» llm èŠ‚ç‚¹è¯»å–é…ç½®ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä»é¡¶å±‚è¯»å–
        llm_config = self.config.get('llm', {})
        model_name = llm_config.get('model', self.config.get('model_name', 'gpt-4o'))  # é»˜è®¤ä½¿ç”¨ gpt-4o
        temperature = llm_config.get('temperature', self.config.get('temperature', 0.3))  # é»˜è®¤æ¸©åº¦ 0.3
        api_key = llm_config.get('api_key') or self.config.get('openai_api_key')  # API å¯†é’¥ (å¯é€‰)
        base_url = llm_config.get('base_url') or self.config.get('openai_base_url')  # åŸºç¡€ URL (å¯é€‰)

        # å¦‚æœä»ç„¶æ²¡æœ‰ API keyï¼Œå°è¯•ä»ç¯å¢ƒå˜é‡è¯»å–
        if not api_key:
            import os
            api_key = os.getenv('OPENAI_API_KEY')

        # ===== åˆå§‹åŒ–æ ¸å¿ƒç»„ä»¶ =====
        # åˆ›å»º HypothesisGenerator å®ä¾‹,è¿™æ˜¯å®é™…æ‰§è¡Œåˆ›æ„ç”Ÿæˆçš„æ ¸å¿ƒç»„ä»¶
        self.hypothesis_generator = HypothesisGenerator(
            model_name=model_name,
            temperature=temperature,
            api_key=api_key,
            base_url=base_url
        )

        # è®¾ç½®æœ€å¤§åˆ›æ„æ•°é‡é™åˆ¶,é¿å…ç”Ÿæˆè¿‡å¤šåˆ›æ„
        # ä¼˜å…ˆä» research_idea.max_ideas è¯»å–ï¼Œå…¶æ¬¡ä»é¡¶å±‚ max_ideasï¼Œæœ€åé»˜è®¤10
        research_idea_config = self.config.get('research_idea', {})
        self.max_ideas = research_idea_config.get('max_ideas', self.config.get('max_ideas', 10))

        # åˆ›å»ºçŸ¥è¯†å›¾è°±æå–å™¨å®ä¾‹,ç”¨äºä»å›¾è°±ä¸­æå–æ•°æ®
        self.kg_extractor = KnowledgeGraphExtractor()

        logger.info(f"ResearchIdeaGenerator initialized with HypothesisGenerator (max_ideas={self.max_ideas})")

    def generate_from_knowledge_graph(
        self,
        graph: nx.Graph,
        topic: str = "",
        min_text_length: int = 50,
        evolutionary_paths: Optional[List[Dict]] = None,
        verbose: bool = True
    ) -> Dict:
        """
        ä»çŸ¥è¯†å›¾è°±ç›´æ¥ç”Ÿæˆç ”ç©¶åˆ›æ„ï¼ˆä¸¤æ­¥æµç¨‹ï¼‰

        ğŸ“‹ æ•´ä½“æµç¨‹ï¼š
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Step 1: è·å– Limitation å’Œ Method                         â”‚
        â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
        â”‚  è¾“å…¥ï¼šçŸ¥è¯†å›¾è°±ï¼ˆå«å¼•ç”¨å…³ç³»ç±»å‹ï¼‰                           â”‚
        â”‚  å¤„ç†ï¼šKnowledgeGraphExtractor.extract_from_graph()       â”‚
        â”‚  - Pool A: æœªè¢« Overcomes çš„ Limitation                   â”‚
        â”‚  - Pool B: è¢« Extends â‰¥2 æ¬¡çš„ Method                      â”‚
        â”‚  - Pool C: æ¥è‡ª Adapts_to çš„ Method                       â”‚
        â”‚  - Pool D: æœªè¢« Realizes çš„ Future Work                   â”‚
        â”‚  è¾“å‡ºï¼š(unsolved_limitations, candidate_methods)           â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Step 2: åˆ›æ„ç”Ÿæˆï¼ˆå«æ¼”åŒ–è·¯å¾„å­¦ä¹  + è‡ªåŠ¨è¿‡æ»¤ï¼‰              â”‚
        â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
        â”‚  è¾“å…¥ï¼šLimitation Ã— Method ç¬›å¡å°”ç§¯ + æ¼”åŒ–è·¯å¾„ï¼ˆå¯é€‰ï¼‰      â”‚
        â”‚  å¤„ç†ï¼šHypothesisGenerator.batch_generate()               â”‚
        â”‚  - å…¼å®¹æ€§åˆ†æ (Compatibility Analysis)                     â”‚
        â”‚  - å·®è·è¯†åˆ« (Gap Identification)                           â”‚
        â”‚  - åˆ›æ„è‰æ‹Ÿ (Idea Drafting)                                â”‚
        â”‚  - æ¼”åŒ–è·¯å¾„å­¦ä¹ ï¼ˆæ–°å¢ï¼‰ï¼š                                   â”‚
        â”‚    * å­¦ä¹ æ¼”åŒ–è„‰ç»œé€»è¾‘ï¼ˆChain/Divergence/Convergenceï¼‰       â”‚
        â”‚    * å­¦ä¹ å¦‚ä½•ç»„åˆ Limitation å’Œ Method                     â”‚
        â”‚    * å‚è€ƒå†å²æˆåŠŸæ¡ˆä¾‹çš„æ¼”åŒ–æ¨¡å¼                             â”‚
        â”‚  - è‡ªåŠ¨è¿‡æ»¤ï¼šåªä¿ç•™ status="SUCCESS" çš„åˆ›æ„                â”‚
        â”‚  è¾“å‡ºï¼šé«˜è´¨é‡å¯è¡Œåˆ›æ„åˆ—è¡¨                                   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

        Args:
            graph: NetworkX å›¾å¯¹è±¡ï¼ŒèŠ‚ç‚¹åº”åŒ…å«è®ºæ–‡ä¿¡æ¯
                   å¿…éœ€çš„èŠ‚ç‚¹å±æ€§ï¼ˆç¢ç‰‡æ± åŒ–ï¼‰:
                   - rag_limitation (str): RAG æå–çš„å±€é™æ€§
                   - rag_future_work (str): RAG æå–çš„æœªæ¥å·¥ä½œ
                   - rag_method (str): RAG æå–çš„è´¡çŒ®/æ–¹æ³•
                   å¿…éœ€çš„è¾¹å±æ€§ï¼ˆç¢ç‰‡æ± åŒ–ï¼‰:
                   - edge_type (str): å¼•ç”¨å…³ç³»ç±»å‹ (Overcomes, Realizes, Extends, Adapts_to)
            topic: ç ”ç©¶ä¸»é¢˜ï¼Œç”¨äºè®°å½•å’Œè¾“å‡ºï¼ˆå¯é€‰ï¼‰
            min_text_length: æ–‡æœ¬æœ€å°é•¿åº¦é˜ˆå€¼ï¼Œé»˜è®¤ 50
                            ç”¨äºè¿‡æ»¤è¿‡çŸ­çš„æ–‡æœ¬ç‰‡æ®µ
            evolutionary_paths: å¯é€‰çš„æ¼”åŒ–è·¯å¾„åˆ—è¡¨ï¼ˆæ¥è‡ª deep_survey_analyzerï¼‰ï¼Œ
                               ç”¨äºæä¾›æ¼”åŒ–ä¸Šä¸‹æ–‡å’Œå­¦ä¹ æ¼”åŒ–é€»è¾‘
            verbose: æ˜¯å¦è¾“å‡ºè¯¦ç»†æ—¥å¿—ï¼Œé»˜è®¤ True

        Returns:
            Dict: åŒ…å«ç”Ÿæˆç»“æœå’Œç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸
                {
                    "topic": str,                    # ç ”ç©¶ä¸»é¢˜
                    "total_ideas": int,              # Step 2 ç”Ÿæˆçš„æ€»åˆ›æ„æ•°
                    "successful_ideas": int,         # Step 2 è¿‡æ»¤åçš„å¯è¡Œåˆ›æ„æ•°
                    "ideas": List[Dict],             # å¯è¡Œåˆ›æ„åˆ—è¡¨ï¼ˆåªå« SUCCESSï¼‰
                    "pools": {
                        "unsolved_limitations": int, # Step 1 æå–çš„å±€é™æ€§æ•°é‡
                        "candidate_methods": int     # Step 1 æå–çš„æ–¹æ³•æ•°é‡
                    }
                }

        Error Handling:
            - ç©ºå›¾è°±ï¼šè¿”å›ç©ºç»“æœå­—å…¸
            - Step 1 æ•°æ®ä¸è¶³ï¼ˆlimitations æˆ– methods ä¸ºç©ºï¼‰ï¼šè¿”å›ç©ºç»“æœå­—å…¸å¹¶è­¦å‘Š

        Example:
            >>> # åˆå§‹åŒ–ç”Ÿæˆå™¨
            >>> generator = ResearchIdeaGenerator(config={'max_ideas': 10})
            >>>
            >>> # ä»çŸ¥è¯†å›¾è°±ç”Ÿæˆåˆ›æ„ï¼ˆä¸¤æ­¥æµç¨‹è‡ªåŠ¨æ‰§è¡Œï¼‰
            >>> # æ–¹å¼1: ä¸ä½¿ç”¨æ¼”åŒ–è·¯å¾„ï¼ˆå‘åå…¼å®¹ï¼‰
            >>> result = generator.generate_from_knowledge_graph(
            ...     graph=citation_graph,
            ...     topic="Transformer Optimization"
            ... )
            >>>
            >>> # æ–¹å¼2: ä½¿ç”¨æ¼”åŒ–è·¯å¾„ï¼ˆæ¨èï¼Œæ›´æ™ºèƒ½ï¼‰
            >>> from deep_survey_analyzer import DeepSurveyAnalyzer
            >>> analyzer = DeepSurveyAnalyzer(config)
            >>> deep_survey_result = analyzer.analyze(citation_graph, "Transformer Optimization")
            >>> evolutionary_paths = deep_survey_result.get('evolutionary_paths', [])
            >>> 
            >>> result = generator.generate_from_knowledge_graph(
            ...     graph=citation_graph,
            ...     topic="Transformer Optimization",
            ...     evolutionary_paths=evolutionary_paths  # æ•´åˆæ¼”åŒ–è·¯å¾„
            ... )
            >>>
            >>> # æŸ¥çœ‹ç»“æœ
            >>> print(f"Step 1: æå–äº† {result['pools']['unsolved_limitations']} ä¸ªé™åˆ¶")
            >>> print(f"Step 1: æå–äº† {result['pools']['candidate_methods']} ä¸ªæ–¹æ³•")
            >>> print(f"Step 2: ç”Ÿæˆäº† {result['total_ideas']} ä¸ªå€™é€‰åˆ›æ„")
            >>> print(f"Step 2: è¿‡æ»¤åå‰©ä½™ {result['successful_ideas']} ä¸ªå¯è¡Œåˆ›æ„")
        """
        # ===== Step 1: è·å– Limitation å’Œ Methodï¼ˆç¢ç‰‡æ± åŒ–ï¼‰=====
        # ä»çŸ¥è¯†å›¾è°±ä¸­æå–é«˜è´¨é‡çš„ç ”ç©¶ç¢ç‰‡
        logger.info("ğŸ“‹ Step 1: ä»çŸ¥è¯†å›¾è°±æå– Limitation å’Œ Method")

        # æ£€æŸ¥å›¾è°±æ˜¯å¦ä¸ºç©º
        if len(graph.nodes()) == 0:
            logger.warning("Knowledge graph is empty, cannot generate ideas")
            # è¿”å›ç©ºç»“æœç»“æ„
            return {
                "topic": topic,
                "total_ideas": 0,
                "successful_ideas": 0,
                "ideas": [],
                "pools": {
                    "unsolved_limitations": 0,
                    "candidate_methods": 0
                }
            }

        # ä½¿ç”¨ KnowledgeGraphExtractor ä»å›¾è°±ä¸­æå– limitations å’Œ methods
        unsolved_limitations, candidate_methods = self.kg_extractor.extract_from_graph(
            graph, min_text_length
        )

        # éªŒè¯æ•°æ®å……åˆ†æ€§
        # éœ€è¦è‡³å°‘ 1 ä¸ª limitation å’Œ 1 ä¸ª method æ‰èƒ½è¿›è¡Œåˆ›æ„ç”Ÿæˆ
        if len(unsolved_limitations) == 0 or len(candidate_methods) == 0:
            logger.warning(
                f"Step 1 æ•°æ®ä¸è¶³: "
                f"{len(unsolved_limitations)} limitations, "
                f"{len(candidate_methods)} methods (need at least 1 of each)"
            )
            # è¿”å›ç©ºç»“æœï¼Œä½†åŒ…å«æå–çš„æ•°é‡ä¿¡æ¯
            return {
                "topic": topic,
                "total_ideas": 0,
                "successful_ideas": 0,
                "ideas": [],
                "pools": {
                    "unsolved_limitations": len(unsolved_limitations),
                    "candidate_methods": len(candidate_methods)
                }
            }

        logger.info(f"âœ… Step 1 å®Œæˆ: {len(unsolved_limitations)} limitations, {len(candidate_methods)} methods")

        # ===== Step 2: åˆ›æ„ç”Ÿæˆï¼ˆå«è‡ªåŠ¨è¿‡æ»¤ï¼‰=====
        # è°ƒç”¨åº•å±‚çš„ generate_from_pools() æ–¹æ³•
        # è¯¥æ–¹æ³•ä¼šè¿›è¡Œ limitation Ã— method çš„ç¬›å¡å°”ç§¯ç»„åˆ
        # å¹¶ä½¿ç”¨ Chain of Thought æ¨ç†ç­›é€‰å¯è¡Œçš„åˆ›æ„
        # åŒæ—¶æ•´åˆæ¼”åŒ–è·¯å¾„ä¿¡æ¯ï¼Œå­¦ä¹ æ¼”åŒ–é€»è¾‘
        logger.info("ğŸ“‹ Step 2: åˆ›æ„ç”Ÿæˆï¼ˆLimitation Ã— Method + CoT æ¨ç† + æ¼”åŒ–è·¯å¾„å­¦ä¹  + è‡ªåŠ¨è¿‡æ»¤ï¼‰")
        
        if evolutionary_paths:
            logger.info(f"  æ•´åˆ {len(evolutionary_paths)} æ¡æ¼”åŒ–è·¯å¾„ä½œä¸ºä¸Šä¸‹æ–‡")

        return self.generate_from_pools(
            unsolved_limitations=unsolved_limitations,
            candidate_methods=candidate_methods,
            topic=topic,
            evolutionary_paths=evolutionary_paths,
            verbose=verbose
        )

    def generate_from_pools(
        self,
        unsolved_limitations: List[str],
        candidate_methods: List[str],
        topic: str = "",
        evolutionary_paths: Optional[List[Dict]] = None,
        verbose: bool = True
    ) -> Dict:
        """
        ä» Limitation å’Œ Method æ± ç”Ÿæˆç ”ç©¶åˆ›æ„ï¼ˆStep 2 çš„å®ç°ï¼‰

        è¯¥æ–¹æ³•æ‰§è¡Œ Step 2 çš„å®Œæ•´æµç¨‹ï¼š
        1. Limitation Ã— Method ç¬›å¡å°”ç§¯ç»„åˆ
        2. Chain of Thought æ¨ç†ï¼ˆå…¼å®¹æ€§åˆ†æ â†’ å·®è·è¯†åˆ« â†’ åˆ›æ„è‰æ‹Ÿï¼‰
        3. æ¼”åŒ–è·¯å¾„å­¦ä¹ ï¼šåˆ©ç”¨æ¼”åŒ–è„‰ç»œçš„é€»è¾‘ï¼Œå­¦ä¹ å¦‚ä½•ç»„åˆ Limitation å’Œ Method
        4. è‡ªåŠ¨è¿‡æ»¤ï¼ˆåªä¿ç•™ status="SUCCESS" çš„åˆ›æ„ï¼‰

        Args:
            unsolved_limitations: Limitation åˆ—è¡¨ï¼ˆæ¥è‡ª Step 1 ç¢ç‰‡æ± åŒ–ï¼‰
            candidate_methods: Method åˆ—è¡¨ï¼ˆæ¥è‡ª Step 1 ç¢ç‰‡æ± åŒ–ï¼‰
            topic: ç ”ç©¶ä¸»é¢˜ï¼ˆå¯é€‰ï¼‰
            evolutionary_paths: å¯é€‰çš„æ¼”åŒ–è·¯å¾„åˆ—è¡¨ï¼ˆæ¥è‡ª deep_survey_analyzerï¼‰ï¼Œ
                               ç”¨äºå­¦ä¹ æ¼”åŒ–é€»è¾‘å’Œæä¾›ä¸Šä¸‹æ–‡
            verbose: æ˜¯å¦è¾“å‡ºè¯¦ç»†è¿›åº¦æ—¥å¿—

        Returns:
            Dict: åŒ…å«ç”Ÿæˆç»“æœå’Œç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸
                {
                    "topic": str,
                    "total_ideas": int,              # ç”Ÿæˆçš„å¯è¡Œåˆ›æ„æ€»æ•°
                    "successful_ideas": int,         # åŒ total_ideasï¼ˆå·²è¿‡æ»¤ï¼‰
                    "ideas": List[Dict],             # åªå« SUCCESS çŠ¶æ€çš„åˆ›æ„
                    "pools": {
                        "unsolved_limitations": int,
                        "candidate_methods": int
                    }
                }
        """
        if verbose:
            logger.info(f"Generating research ideas for topic: {topic}")
            logger.info(f"Limitations pool: {len(unsolved_limitations)}")
            logger.info(f"Methods pool: {len(candidate_methods)}")
            if evolutionary_paths:
                logger.info(f"Evolutionary paths: {len(evolutionary_paths)} paths provided")

        # è°ƒç”¨ HypothesisGenerator è¿›è¡Œæ‰¹é‡ç”Ÿæˆ
        # batch_generate å†…éƒ¨ä¼šï¼š
        # 1. è¿›è¡Œ limitation Ã— method ç¬›å¡å°”ç§¯éå†
        # 2. å¯¹æ¯ä¸ªç»„åˆè°ƒç”¨ Chain of Thought æ¨ç†
        # 3. æ•´åˆæ¼”åŒ–è·¯å¾„ä¿¡æ¯ï¼Œå­¦ä¹ æ¼”åŒ–é€»è¾‘
        # 4. è‡ªåŠ¨è¿‡æ»¤ï¼Œåªè¿”å› status="SUCCESS" çš„åˆ›æ„
        ideas = self.hypothesis_generator.batch_generate(
            unsolved_limitations=unsolved_limitations,
            candidate_methods=candidate_methods,
            evolutionary_paths=evolutionary_paths,
            max_ideas=self.max_ideas,
            verbose=verbose
        )

        return {
            "topic": topic,
            "total_ideas": len(ideas),
            "successful_ideas": len([i for i in ideas if i["status"] == "SUCCESS"]),
            "ideas": ideas,
            "pools": {
                "unsolved_limitations": len(unsolved_limitations),
                "candidate_methods": len(candidate_methods)
            }
        }


# ä¾¿æ·å‡½æ•°ï¼Œç”¨äºç›´æ¥ä½¿ç”¨
def generate_innovation_idea(
    limitation: str,
    method: str,
    model_name: str = "gpt-4o",
    temperature: float = 0.3,
    api_key: Optional[str] = None,
    base_url: Optional[str] = None,
    evolutionary_paths: Optional[List[Dict]] = None,
    verbose: bool = False
) -> Dict:
    """
    ä¾¿æ·å‡½æ•°ï¼Œç”¨äºç”Ÿæˆå•ä¸ªåˆ›æ–°åˆ›æ„

    Args:
        limitation: ç ”ç©¶é™åˆ¶/ç“¶é¢ˆæè¿°
        method: å€™é€‰æ–¹æ³•æè¿°
        model_name: è¦ä½¿ç”¨çš„ OpenAI æ¨¡å‹
        temperature: é‡‡æ ·æ¸©åº¦
        api_key: OpenAI API å¯†é’¥
        base_url: å¯é€‰çš„ API åŸºç¡€ URL
        evolutionary_paths: å¯é€‰çš„æ¼”åŒ–è·¯å¾„åˆ—è¡¨ï¼Œç”¨äºæä¾›ä¸Šä¸‹æ–‡å’Œå­¦ä¹ æ¼”åŒ–é€»è¾‘
        verbose: æ‰“å°è¯¦ç»†è¾“å‡º

    Returns:
        åŒ…å« statusã€titleã€abstractã€modificationã€reasoning å’Œ rationale çš„å­—å…¸
        rationale å­—æ®µåŒ…å«å®Œæ•´çš„æ¨æ¼”è·¯å¾„ï¼ŒåŒ…æ‹¬Step 1-3çš„è¯¦ç»†åˆ†æ

    Example:
        >>> idea = generate_innovation_idea(
        ...     limitation="æ ‡å‡†æ³¨æ„åŠ›æœºåˆ¶å…·æœ‰ O(nÂ²) å¤æ‚åº¦",
        ...     method="FlashAttention ä½¿ç”¨åˆ†å—æ¥å‡å°‘å†…å­˜ IO æ“ä½œ"
        ... )
        >>> print(idea["status"])  # "SUCCESS" æˆ– "INCOMPATIBLE"
        >>> print(idea["title"])
        >>> print(idea["abstract"])
    """
    generator = HypothesisGenerator(
        model_name=model_name,
        temperature=temperature,
        api_key=api_key,
        base_url=base_url
    )

    return generator.generate_innovation_idea(
        limitation, 
        method, 
        evolutionary_paths=evolutionary_paths,
        verbose=verbose
    )


if __name__ == "__main__":
    # ç¤ºä¾‹ç”¨æ³•
    logging.basicConfig(level=logging.INFO)

    # ç¤ºä¾‹ 1: å•ä¸ªåˆ›æ„ç”Ÿæˆ
    print("\n" + "="*80)
    print("ç¤ºä¾‹ 1: å•ä¸ªåˆ›æ„ç”Ÿæˆ")
    print("="*80)

    limitation = "Transformerä¸­çš„æ ‡å‡†æ³¨æ„åŠ›æœºåˆ¶åœ¨åºåˆ—é•¿åº¦ä¸Šå…·æœ‰äºŒæ¬¡è®¡ç®—å¤æ‚åº¦ O(nÂ²)ï¼Œé™åˆ¶äº†å…¶åœ¨é•¿åºåˆ—ä¸Šçš„åº”ç”¨ã€‚"

    method = "FlashAttention ä½¿ç”¨åˆ†å—å’Œé‡è®¡ç®—ç­–ç•¥æ¥å‡å°‘å†…å­˜IOæ“ä½œï¼Œåœ¨ä¿æŒç²¾ç¡®æ³¨æ„åŠ›è®¡ç®—çš„åŒæ—¶å®ç°äº†æ˜¾è‘—çš„åŠ é€Ÿã€‚"

    idea = generate_innovation_idea(limitation, method, verbose=True)

    print("\nç»“æœ:")
    print(json.dumps(idea, indent=2, ensure_ascii=False))

    # ç¤ºä¾‹ 2: æ‰¹é‡ç”Ÿæˆ
    print("\n\n" + "="*80)
    print("ç¤ºä¾‹ 2: æ‰¹é‡åˆ›æ„ç”Ÿæˆ")
    print("="*80)

    limitations = [
        "å½“å‰çš„è§†è§‰Transformeréœ€è¦å¤§é‡è®­ç»ƒæ•°æ®ï¼Œåœ¨å°æ•°æ®é›†ä¸Šè¡¨ç°ä¸ä½³ã€‚",
        "å›¾ç¥ç»ç½‘ç»œåœ¨å †å å¤šå±‚æ—¶ä¼šå‡ºç°è¿‡åº¦å¹³æ»‘é—®é¢˜ã€‚",
        "å¼ºåŒ–å­¦ä¹ ç®—æ³•åœ¨ç¨€ç–å¥–åŠ±ç¯å¢ƒä¸­å…·æœ‰é«˜æ ·æœ¬å¤æ‚åº¦ã€‚"
    ]

    methods = [
        "ä½¿ç”¨å¯¹æ¯”ç›®æ ‡çš„è‡ªç›‘ç£å­¦ä¹ å¯ä»¥åœ¨æ²¡æœ‰æ ‡ç­¾çš„æƒ…å†µä¸‹å­¦ä¹ æœ‰ç”¨çš„è¡¨ç¤ºã€‚",
        "æ³¨æ„åŠ›æœºåˆ¶å¯ä»¥é€‰æ‹©æ€§åœ°å…³æ³¨è¾“å…¥çš„ç›¸å…³éƒ¨åˆ†ã€‚",
        "å…ƒå­¦ä¹ ç®—æ³•å¯ä»¥ç”¨å°‘é‡ç¤ºä¾‹å¿«é€Ÿé€‚åº”æ–°ä»»åŠ¡ã€‚"
    ]

    generator = HypothesisGenerator(model_name="gpt-4o", temperature=0.3)
    ideas = generator.batch_generate(
        unsolved_limitations=limitations,
        candidate_methods=methods,
        max_ideas=5,
        verbose=True
    )

    print(f"\n\nç”Ÿæˆäº† {len(ideas)} ä¸ªæˆåŠŸçš„åˆ›æ„:")
    for i, idea in enumerate(ideas, 1):
        print(f"\n{'='*80}")
        print(f"åˆ›æ„ {i}")
        print(f"{'='*80}")
        print(f"æ ‡é¢˜: {idea['title']}")
        print(f"æ‘˜è¦: {idea['abstract'][:200]}...")
        print(f"å…³é”®ä¿®æ”¹: {idea['modification']}")
