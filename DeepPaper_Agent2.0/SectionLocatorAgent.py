"""
Section Locator Agent (ç« èŠ‚å®šä½å‘˜)
è´Ÿè´£å®šä½ limitation å’Œ future work ç« èŠ‚

å‚è€ƒ DeepPaper_Agent çš„ NavigatorAgent å®ç°
ä½¿ç”¨ LLM æˆ–è§„åˆ™å®šä½ç›®æ ‡ç« èŠ‚
"""

import json
import logging
import re
from typing import List, Dict, Optional, Any
from pathlib import Path

# å¯¼å…¥æ•°æ®ç»“æ„
from data_structures import PaperDocument, PaperSection, SectionScope, FieldType

# å¯¼å…¥LLMé…ç½®
import sys
sys.path.append(str(Path(__file__).parent.parent))
from src.llm_config import LLMClient, LLMConfig

logger = logging.getLogger(__name__)


class SectionLocatorAgent:
    """
    ç« èŠ‚å®šä½ Agent
    ç”¨äºå®šä½ limitation å’Œ future work æ‰€åœ¨çš„ç« èŠ‚
    """

    def __init__(self, llm_client: Optional[LLMClient] = None):
        """
        åˆå§‹åŒ–ç« èŠ‚å®šä½å‘˜

        Args:
            llm_client: LLMå®¢æˆ·ç«¯ï¼ˆå¯é€‰ï¼Œç”¨äºæ™ºèƒ½å®šä½ï¼‰
        """
        self.llm_client = llm_client
        self.system_prompt = self._build_system_prompt() if llm_client else None

        # é¢„å®šä¹‰çš„ç« èŠ‚æ˜ å°„ï¼ˆä½œä¸ºfallbackï¼‰
        self.section_mapping = {
            FieldType.LIMITATION: ['limitation', 'discussion', 'conclusion'],
            FieldType.FUTURE_WORK: ['future_work', 'future work', 'conclusion', 'discussion']
        }

    def _build_system_prompt(self) -> str:
        """æ„å»ºç³»ç»Ÿæç¤ºè¯"""
        return """You are an expert in analyzing the structure of academic papers.

Your Task: Accurately locate specific information within the paper.

Input Description:

The paper consists of multiple sections.
Each section has a title and a section_type.
You need to determine the location of the target information based on the section title, type, and content preview.
Key Distinctions:

Limitation: The authors admit the shortcomings of their own method (not criticizing prior work).
Future Work: Future research directions proposed by the authors.
Notes:

Limitations and Future Work often appear at the end of the Discussion or Conclusion sections.
Look for transition words: However, Unfortunately, Future work, remains to be.
The output must be in valid JSON format.
Output Format:
{
    "target_sections": [list of section indices],
    "reasoning": "reasoning process",
    "confidence": 0.0-1.0
}
"""

    def locate(
        self,
        paper: PaperDocument,
        field: FieldType
    ) -> SectionScope:
        """
        å®šä½æŒ‡å®šå­—æ®µæ‰€åœ¨çš„ç« èŠ‚

        Args:
            paper: è®ºæ–‡æ–‡æ¡£
            field: å­—æ®µç±»å‹ (LIMITATION æˆ– FUTURE_WORK)

        Returns:
            SectionScope: ç« èŠ‚èŒƒå›´
        """
        logger.info(f"ğŸ” å®šä½å­—æ®µ '{field.value}' çš„ç« èŠ‚...")

        # æ„å»ºç« èŠ‚æ¦‚è§ˆ
        structure_overview = self._build_structure_overview(paper)

        # ä½¿ç”¨LLMæˆ–è§„åˆ™å®šä½
        if self.llm_client:
            scope = self._locate_with_llm(paper, field, structure_overview)
        else:
            scope = self._locate_with_rules(paper, field)

        logger.info(f"   âœ… å®šä½åˆ° {len(scope.target_sections)} ä¸ªç« èŠ‚: {scope.section_titles}")
        return scope

    def _build_structure_overview(self, paper: PaperDocument) -> str:
        """
        æ„å»ºè®ºæ–‡ç»“æ„æ¦‚è§ˆ

        åŒ…å«:
        - æ ‡é¢˜å’Œæ‘˜è¦
        - ç« èŠ‚åˆ—è¡¨ï¼ˆæ ‡é¢˜ã€ç±»å‹ã€é¦–å°¾æ®µè½é¢„è§ˆï¼‰
        """
        overview_parts = [
            f"Paper Title: {paper.title}",
            f"Total Sections: {len(paper.sections)}",
        ]

        # æ·»åŠ æ‘˜è¦é¢„è§ˆ
        if paper.abstract:
            abstract_preview = paper.abstract[:300] if len(paper.abstract) > 300 else paper.abstract
            overview_parts.append(f"\nAbstract Preview:\n{abstract_preview}...")

        overview_parts.append("\n" + "=" * 60)
        overview_parts.append("Section Structure:")
        overview_parts.append("=" * 60)

        for i, section in enumerate(paper.sections):
            section_type = section.section_type if section.section_type != 'other' else 'unknown'
            content_length = len(section.content)

            # æå–é¦–æ®µå’Œå°¾æ®µ
            paragraphs = [p.strip() for p in section.content.split('\n\n') if p.strip()]
            first_para = paragraphs[0][:150] if paragraphs else ""
            last_para = paragraphs[-1][:150] if len(paragraphs) > 1 else ""

            section_info = [
                f"\n[{i}] {section.title}",
                f"    Type: {section_type} | Length: {content_length} chars",
            ]

            if first_para:
                section_info.append(f"    First: {first_para}...")

            # å¯¹äºå¯èƒ½åŒ…å«limitation/future workçš„ç« èŠ‚ï¼Œæ˜¾ç¤ºå°¾æ®µ
            if section_type in ['discussion', 'conclusion', 'limitation', 'future_work', 'unknown']:
                if last_para and last_para != first_para:
                    section_info.append(f"    Last: {last_para}...")

            overview_parts.append('\n'.join(section_info))

        return "\n".join(overview_parts)

    def _locate_with_llm(
        self,
        paper: PaperDocument,
        field: FieldType,
        structure_overview: str
    ) -> SectionScope:
        """
        ä½¿ç”¨LLMè¿›è¡Œæ™ºèƒ½å®šä½
        """
        prompt = self._build_locator_prompt(field, structure_overview)

        try:
            response = self.llm_client.generate(
                prompt=prompt,
                system_prompt=self.system_prompt,
                temperature=0.2,
                max_tokens=1000
            )

            # è§£æå“åº”
            scope = self._parse_llm_response(response, paper, field)
            return scope

        except Exception as e:
            logger.warning(f"   âš ï¸ LLMå®šä½å¤±è´¥: {e}, é™çº§åˆ°è§„åˆ™åŒ¹é…")
            return self._locate_with_rules(paper, field)

    def _build_locator_prompt(self, field: FieldType, structure_overview: str) -> str:
        """æ„å»ºå®šä½æç¤ºè¯"""
        field_descriptions = {
            FieldType.LIMITATION: "æœ¬æ–‡æ–¹æ³•çš„å±€é™æ€§ï¼ˆä¸æ˜¯å‰äººå·¥ä½œçš„ç¼ºç‚¹ï¼‰",
            FieldType.FUTURE_WORK: "æœªæ¥å·¥ä½œæ–¹å‘/å¾…æ”¹è¿›çš„ç‚¹"
        }

        field_hints = {
            FieldType.LIMITATION: """âš ï¸ é‡è¦! å¯èƒ½éšè—åœ¨Discussion/Conclusionæœ«å°¾çš„è½¬æŠ˜è¯åã€‚
            - æ£€æŸ¥typeä¸º'discussion'/'conclusion'çš„ç« èŠ‚çš„Lastæ®µè½
            - å¯»æ‰¾: However, Unfortunately, Limitation, remains to be
            - æ³¨æ„: åªè¦æœ¬æ–‡æ–¹æ³•çš„å±€é™æ€§,ä¸è¦baselineçš„ç¼ºç‚¹""",

            FieldType.FUTURE_WORK: """å¯èƒ½åœ¨ç‹¬ç«‹çš„Future Workç« èŠ‚,æˆ–Conclusion/Discussionçš„ç»“å°¾ã€‚
            - æ£€æŸ¥typeä¸º'future_work'çš„ç« èŠ‚(å¦‚æœæœ‰)
            - å¦åˆ™æ£€æŸ¥'conclusion'/'discussion'ç« èŠ‚çš„Lastæ®µè½
            - å¯»æ‰¾: future, next, further, explore, plan"""
        }

        prompt = f"""ä½ æ˜¯ä¸€ä¸ªèµ„æ·±ç ”ç©¶å‘˜,éœ€è¦åˆ†æè®ºæ–‡ç»“æ„å¹¶å®šä½å…³é”®ä¿¡æ¯ã€‚

ç›®æ ‡å­—æ®µ: {field.value}
å­—æ®µå®šä¹‰: {field_descriptions[field]}
æœç´¢æç¤º: {field_hints[field]}

è®ºæ–‡ç»“æ„:
{structure_overview}

ä»»åŠ¡:
1. åˆ†ææ¯ä¸ªç« èŠ‚çš„Title, Type, å’Œå†…å®¹é¢„è§ˆ
2. æ‰¾å‡ºæœ€å¯èƒ½åŒ…å«'{field.value}'çš„ç« èŠ‚(è¿”å›ç« èŠ‚ç´¢å¼•)
3. ç‰¹åˆ«å…³æ³¨Discussion/Conclusionç« èŠ‚çš„å°¾æ®µ
4. ç»™å‡ºä½ çš„æ¨ç†è¿‡ç¨‹

è¾“å‡ºæ ¼å¼(JSON):
{{
    "target_sections": [ç« èŠ‚ç´¢å¼•åˆ—è¡¨],
    "reasoning": "ä½ çš„æ¨ç†è¿‡ç¨‹",
    "confidence": 0.0-1.0
}}

è¯·è¾“å‡º:"""

        return prompt

    def _parse_llm_response(
        self,
        response: str,
        paper: PaperDocument,
        field: FieldType
    ) -> SectionScope:
        """è§£æLLMå“åº”"""
        try:
            # æå–JSON
            json_str = self._extract_json(response)
            result = json.loads(json_str)

            target_sections = result.get('target_sections', [])
            reasoning = result.get('reasoning', 'No reasoning provided')
            confidence = result.get('confidence', 0.5)

            # éªŒè¯ç« èŠ‚ç´¢å¼•
            target_sections = [
                idx for idx in target_sections
                if 0 <= idx < len(paper.sections)
            ]

            if not target_sections:
                # é™çº§åˆ°è§„åˆ™
                return self._locate_with_rules(paper, field)

            section_titles = [paper.sections[idx].title for idx in target_sections]

            return SectionScope(
                field=field,
                target_sections=target_sections,
                section_titles=section_titles,
                reasoning=reasoning,
                confidence=confidence
            )

        except Exception as e:
            logger.warning(f"   âš ï¸ è§£æLLMå“åº”å¤±è´¥: {e}")
            return self._locate_with_rules(paper, field)

    def _extract_json(self, text: str) -> str:
        """ä»æ–‡æœ¬ä¸­æå–JSONå†…å®¹"""
        # å°è¯•æ‰¾åˆ°JSONä»£ç å—
        if "```json" in text:
            start = text.find("```json") + 7
            end = text.find("```", start)
            if end != -1:
                return text[start:end].strip()

        # å°è¯•æ‰¾åˆ°èŠ±æ‹¬å·åŒ…å›´çš„å†…å®¹
        start = text.find("{")
        end = text.rfind("}") + 1
        if start != -1 and end > start:
            return text[start:end]

        return text.strip()

    def _locate_with_rules(self, paper: PaperDocument, field: FieldType) -> SectionScope:
        """
        ä½¿ç”¨è§„åˆ™åŒ¹é…è¿›è¡Œå®šä½ï¼ˆfallbackï¼‰

        ç­–ç•¥:
        1. é¦–å…ˆæŒ‰ç« èŠ‚ç±»å‹åŒ¹é…
        2. å¦‚æœå¤±è´¥ï¼ŒæŒ‰æ ‡é¢˜å…³é”®è¯åŒ¹é…
        3. å¦‚æœè¿˜æ˜¯å¤±è´¥ï¼Œè¿”å›æœ€åå‡ ä¸ªç« èŠ‚
        """
        target_types = self.section_mapping.get(field, [])

        target_sections = []
        section_titles = []

        # æ­¥éª¤1: æŒ‰ç« èŠ‚ç±»å‹åŒ¹é…
        for i, section in enumerate(paper.sections):
            if section.section_type in target_types:
                target_sections.append(i)
                section_titles.append(section.title)

        # æ­¥éª¤2: å¦‚æœå¤±è´¥ï¼Œä½¿ç”¨æ ‡é¢˜åŒ¹é…
        if not target_sections:
            logger.info(f"   â†’ ç±»å‹åŒ¹é…å¤±è´¥,å°è¯•æ ‡é¢˜åŒ¹é…...")
            target_sections, section_titles = self._match_by_title(paper, field)

        # æ­¥éª¤3: å¦‚æœè¿˜æ˜¯å¤±è´¥ï¼Œè¿”å›æœ€åå‡ ä¸ªç« èŠ‚ï¼ˆlimitation/future worké€šå¸¸åœ¨ç»“å°¾ï¼‰
        if not target_sections:
            logger.warning(f"   â†’ æ ‡é¢˜åŒ¹é…ä¹Ÿå¤±è´¥,ä½¿ç”¨æœ€å3ä¸ªç« èŠ‚ä½œä¸ºé»˜è®¤èŒƒå›´")
            target_sections = list(range(max(0, len(paper.sections) - 3), len(paper.sections)))
            section_titles = [paper.sections[i].title for i in target_sections]

        return SectionScope(
            field=field,
            target_sections=target_sections,
            section_titles=section_titles,
            reasoning=f"Rule-based matching for {field.value} using section types: {target_types}",
            confidence=0.6
        )

    def _match_by_title(self, paper: PaperDocument, field: FieldType) -> tuple:
        """æ ¹æ®ç« èŠ‚æ ‡é¢˜åŒ¹é…"""
        title_keywords_map = {
            FieldType.LIMITATION: [
                'limitation', 'discussion', 'conclusion',
                'summary', 'result', 'drawback'
            ],
            FieldType.FUTURE_WORK: [
                'future', 'conclusion', 'discussion',
                'outlook', 'direction', 'next step', 'ongoing'
            ]
        }

        keywords = title_keywords_map.get(field, [])

        target_sections = []
        section_titles = []

        for i, section in enumerate(paper.sections):
            title_lower = section.title.lower()
            # æ£€æŸ¥æ ‡é¢˜æ˜¯å¦åŒ…å«ä»»ä½•å…³é”®è¯
            if any(kw in title_lower for kw in keywords):
                target_sections.append(i)
                section_titles.append(section.title)

        logger.info(f"   â†’ æ ‡é¢˜åŒ¹é…æ‰¾åˆ° {len(target_sections)} ä¸ªç« èŠ‚")

        return target_sections, section_titles


def main():
    """æµ‹è¯•ä»£ç """
    import argparse
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )

    parser = argparse.ArgumentParser(description="Section Locator Agent - ç« èŠ‚å®šä½")
    parser.add_argument("--config", help="LLMé…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰")
    parser.add_argument("--paper", required=True, help="è®ºæ–‡æ–‡æœ¬æ–‡ä»¶è·¯å¾„ï¼ˆJSONæ ¼å¼ï¼‰")
    parser.add_argument("--field", required=True, choices=["limitation", "future_work"],
                        help="è¦å®šä½çš„å­—æ®µç±»å‹")

    args = parser.parse_args()

    try:
        # åˆå§‹åŒ–LLMå®¢æˆ·ç«¯ï¼ˆå¦‚æœæä¾›é…ç½®ï¼‰
        llm_client = None
        if args.config:
            config = LLMConfig.from_file(args.config)
            llm_client = LLMClient(config)

        # è¯»å–è®ºæ–‡æ–‡æ¡£
        with open(args.paper, 'r', encoding='utf-8') as f:
            paper_data = json.load(f)

        # è½¬æ¢ä¸ºPaperDocumentå¯¹è±¡
        sections = [
            PaperSection(**section) for section in paper_data.get('sections', [])
        ]
        paper = PaperDocument(
            paper_id=paper_data.get('paper_id', 'unknown'),
            title=paper_data.get('title', ''),
            abstract=paper_data.get('abstract', ''),
            authors=paper_data.get('authors', []),
            year=paper_data.get('year'),
            sections=sections,
            metadata=paper_data.get('metadata')
        )

        # åˆ›å»ºå®šä½agent
        field_type = FieldType.LIMITATION if args.field == "limitation" else FieldType.FUTURE_WORK
        agent = SectionLocatorAgent(llm_client)

        # æ‰§è¡Œå®šä½
        scope = agent.locate(paper, field_type)

        # æ‰“å°ç»“æœ
        print("\n" + "=" * 80)
        print(f"Section Locator Results for '{field_type.value}'")
        print("=" * 80)
        print(f"\nTarget Sections: {scope.target_sections}")
        print(f"Section Titles: {scope.section_titles}")
        print(f"Confidence: {scope.confidence:.2f}")
        print(f"\nReasoning:\n{scope.reasoning}")

    except Exception as e:
        logger.error(f"æ‰§è¡Œå¤±è´¥: {e}")
        raise


if __name__ == "__main__":
    main()
