"""
Logic Analyst Agent (é€»è¾‘åˆ†æå‘˜)
è´Ÿè´£å†…éƒ¨é€»è¾‘ï¼Œå¯»æ‰¾"é—®é¢˜ä¸è§£æ³•"çš„æ˜ å°„

èŒè´£ï¼šåˆ†æè®ºæ–‡æ ¸å¿ƒé€»è¾‘ï¼Œæå– Problem-Solution (P-S) Pairs
è¾“å…¥ï¼šè®ºæ–‡å…¨æ–‡ï¼ˆæˆ– Abstract + Intro + Method æ ¸å¿ƒæ®µè½ï¼‰
è¾“å‡ºï¼šç»“æ„åŒ–çš„ Problem-Solution Pairs
"""

import json
import logging
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, asdict
from pathlib import Path

# å¯¼å…¥LLMé…ç½®
import sys
sys.path.append(str(Path(__file__).parent.parent))
from src.llm_config import LLMClient, LLMConfig

logger = logging.getLogger(__name__)


@dataclass
class ProblemSolutionPair:
    """é—®é¢˜-è§£æ³•å¯¹æ•°æ®ç»“æ„"""
    problem: str  # æ ¸å¿ƒç—›ç‚¹ (The Lock)
    solution: str  # æ ¸å¿ƒæœºåˆ¶ (The Key)
    explanation: str  # æœºåˆ¶å¦‚ä½•è§£å†³ç—›ç‚¹çš„è§£é‡Š
    confidence: float = 0.0  # ç½®ä¿¡åº¦ (0-1)
    evidence: Optional[str] = None  # æ”¯æŒè¯æ®ï¼ˆè®ºæ–‡ä¸­çš„åŸæ–‡å¼•ç”¨ï¼‰

    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return asdict(self)


class LogicAnalystAgent:
    """
    Logic Analyst Agent
    è´Ÿè´£åˆ†æè®ºæ–‡çš„æ ¸å¿ƒé€»è¾‘ï¼Œæå–é—®é¢˜-è§£æ³•æ˜ å°„å…³ç³»
    """

    def __init__(self, llm_client: LLMClient):
        """
        åˆå§‹åŒ–é€»è¾‘åˆ†æå‘˜

        Args:
            llm_client: LLMå®¢æˆ·ç«¯
        """
        self.llm_client = llm_client
        self.system_prompt = self._build_system_prompt()

    def _build_system_prompt(self) -> str:
        """æ„å»ºç³»ç»Ÿæç¤ºè¯"""
        return """You are a professional expert in scientific paper logic analysis.

Your Task:

Read the paper content and identify the core pain point (The Lock/Problem) the authors aim to solve.
Identify the core mechanism/solution (The Key/Solution) designed by the authors.
Explain specifically how this mechanism addresses the pain point.
Output Requirements:

Output in the form of "Problem-Solution Pairs".
Problem descriptions must be precise and specific, avoiding generalizations.
Solution descriptions must focus on the core mechanism, avoiding the listing of irrelevant technical details.
You must clearly explain the causal relationship of "how the solution solves the problem".
If there are multiple pairs, list them separately (focusing on the core 1-3 pairs).
Output Format (JSON):
{
    "pairs": [
        {
            "problem": "Description of the problem",
            "solution": "Description of the solution/mechanism",
            "explanation": "Detailed explanation of how the solution solves the problem",
            "confidence": 0.9,
            "evidence": "Citation from original text (optional)"
        }
    ]
}
Note:

Do not generate problems irrelevant to the core innovation.
Do not simply repeat the abstract; distill the logical relationships.
Focus on "why this design solves this problem".
"""

    def analyze(
        self,
        paper_content: str,
        paper_metadata: Optional[Dict[str, Any]] = None
    ) -> List[ProblemSolutionPair]:
        """
        åˆ†æè®ºæ–‡ï¼Œæå–é—®é¢˜-è§£æ³•å¯¹

        Args:
            paper_content: è®ºæ–‡å†…å®¹ï¼ˆå…¨æ–‡æˆ–å…³é”®æ®µè½ï¼‰
            paper_metadata: è®ºæ–‡å…ƒæ•°æ®ï¼ˆå¯é€‰ï¼Œå¦‚æ ‡é¢˜ã€ä½œè€…ç­‰ï¼‰

        Returns:
            é—®é¢˜-è§£æ³•å¯¹åˆ—è¡¨
        """
        logger.info("å¼€å§‹é€»è¾‘åˆ†æï¼šæå– Problem-Solution Pairs")

        # æ„å»ºåˆ†ææç¤ºè¯
        user_prompt = self._build_analysis_prompt(paper_content, paper_metadata)

        # è°ƒç”¨LLMåˆ†æ
        try:
            response = self.llm_client.generate(
                prompt=user_prompt,
                system_prompt=self.system_prompt,
                temperature=0.3,  # è¾ƒä½æ¸©åº¦ä¿è¯é€»è¾‘ä¸€è‡´æ€§
                max_tokens=2000
            )

            # è§£æå“åº”
            pairs = self._parse_response(response)

            logger.info(f"âœ… æå–åˆ° {len(pairs)} ä¸ª Problem-Solution Pairs")
            return pairs

        except Exception as e:
            logger.error(f"é€»è¾‘åˆ†æå¤±è´¥: {e}")
            return []

    def _build_analysis_prompt(
        self,
        paper_content: str,
        paper_metadata: Optional[Dict[str, Any]]
    ) -> str:
        """æ„å»ºåˆ†ææç¤ºè¯"""
        prompt_parts = []

        # æ·»åŠ å…ƒæ•°æ®ä¿¡æ¯
        if paper_metadata:
            prompt_parts.append("ã€è®ºæ–‡ä¿¡æ¯ã€‘")
            if "title" in paper_metadata:
                prompt_parts.append(f"æ ‡é¢˜: {paper_metadata['title']}")
            if "authors" in paper_metadata:
                prompt_parts.append(f"ä½œè€…: {', '.join(paper_metadata['authors'])}")
            if "year" in paper_metadata:
                prompt_parts.append(f"å¹´ä»½: {paper_metadata['year']}")
            prompt_parts.append("")

        # æ·»åŠ è®ºæ–‡å†…å®¹
        prompt_parts.append("ã€è®ºæ–‡å†…å®¹ã€‘")
        prompt_parts.append(paper_content)
        prompt_parts.append("")

        # æ·»åŠ åˆ†ææŒ‡ä»¤
        prompt_parts.append("ã€åˆ†æä»»åŠ¡ã€‘")
        prompt_parts.append("è¯·åˆ†æä»¥ä¸Šè®ºæ–‡ï¼Œæ‰¾å‡ºæ ¸å¿ƒçš„ Problem-Solution Pairsã€‚")
        prompt_parts.append("è¯·ä»¥JSONæ ¼å¼è¾“å‡ºï¼ŒåŒ…å« pairs æ•°ç»„ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«ï¼š")
        prompt_parts.append("- problem: æ ¸å¿ƒç—›ç‚¹æè¿°")
        prompt_parts.append("- solution: æ ¸å¿ƒæœºåˆ¶æè¿°")
        prompt_parts.append("- explanation: æœºåˆ¶å¦‚ä½•è§£å†³ç—›ç‚¹çš„è¯¦ç»†è§£é‡Š")
        prompt_parts.append("- confidence: ç½®ä¿¡åº¦ (0-1)")
        prompt_parts.append("- evidence: è®ºæ–‡åŸæ–‡å¼•ç”¨ï¼ˆå¯é€‰ï¼‰")

        return "\n".join(prompt_parts)

    def _parse_response(self, response: str) -> List[ProblemSolutionPair]:
        """
        è§£æLLMå“åº”ï¼Œæå–é—®é¢˜-è§£æ³•å¯¹

        Args:
            response: LLMåŸå§‹å“åº”

        Returns:
            é—®é¢˜-è§£æ³•å¯¹åˆ—è¡¨
        """
        pairs = []

        try:
            # å°è¯•æå–JSON
            json_str = self._extract_json(response)
            data = json.loads(json_str)

            # è§£æpairsæ•°ç»„
            if "pairs" in data and isinstance(data["pairs"], list):
                for pair_data in data["pairs"]:
                    pair = ProblemSolutionPair(
                        problem=pair_data.get("problem", ""),
                        solution=pair_data.get("solution", ""),
                        explanation=pair_data.get("explanation", ""),
                        confidence=float(pair_data.get("confidence", 0.0)),
                        evidence=pair_data.get("evidence")
                    )
                    pairs.append(pair)

            logger.info(f"æˆåŠŸè§£æ {len(pairs)} ä¸ª Problem-Solution Pairs")

        except json.JSONDecodeError as e:
            logger.warning(f"JSONè§£æå¤±è´¥: {e}")
            # å°è¯•ä»æ–‡æœ¬ä¸­æå–
            pairs = self._fallback_parse(response)

        except Exception as e:
            logger.error(f"å“åº”è§£æå¤±è´¥: {e}")

        return pairs

    def _extract_json(self, text: str) -> str:
        """
        ä»æ–‡æœ¬ä¸­æå–JSONå†…å®¹

        Args:
            text: åŒ…å«JSONçš„æ–‡æœ¬

        Returns:
            JSONå­—ç¬¦ä¸²
        """
        # å°è¯•æ‰¾åˆ°JSONä»£ç å—
        if "```json" in text:
            start = text.find("```json") + 7
            end = text.find("```", start)
            if end != -1:
                return text[start:end].strip()

        # å°è¯•æ‰¾åˆ°èŠ±æ‹¬å·åŒ…å›´çš„å†…å®¹
        start = text.find("{")
        end = text.rfind("}") + 1
        if start != -1 and end > start:
            return text[start:end]

        return text.strip()

    def _fallback_parse(self, response: str) -> List[ProblemSolutionPair]:
        """
        åå¤‡è§£ææ–¹æ³•ï¼šä»æ–‡æœ¬ä¸­æå–é—®é¢˜-è§£æ³•å¯¹

        Args:
            response: LLMå“åº”æ–‡æœ¬

        Returns:
            é—®é¢˜-è§£æ³•å¯¹åˆ—è¡¨
        """
        logger.info("ä½¿ç”¨åå¤‡è§£ææ–¹æ³•æå– Problem-Solution Pairs")

        pairs = []

        # ç®€å•çš„æ–‡æœ¬è§£æé€»è¾‘ï¼ˆå¯ä»¥æ ¹æ®å®é™…å“åº”æ ¼å¼ä¼˜åŒ–ï¼‰
        lines = response.split("\n")
        current_problem = None
        current_solution = None
        current_explanation = None

        for line in lines:
            line = line.strip()

            if line.lower().startswith("problem:") or line.lower().startswith("é—®é¢˜:"):
                current_problem = line.split(":", 1)[1].strip()

            elif line.lower().startswith("solution:") or line.lower().startswith("è§£æ³•:"):
                current_solution = line.split(":", 1)[1].strip()

            elif line.lower().startswith("explanation:") or line.lower().startswith("è§£é‡Š:"):
                current_explanation = line.split(":", 1)[1].strip()

                # å½“æ”¶é›†åˆ°å®Œæ•´çš„ä¸‰å…ƒç»„æ—¶ï¼Œåˆ›å»ºpair
                if current_problem and current_solution and current_explanation:
                    pair = ProblemSolutionPair(
                        problem=current_problem,
                        solution=current_solution,
                        explanation=current_explanation,
                        confidence=0.5  # åå¤‡è§£æç½®ä¿¡åº¦è¾ƒä½
                    )
                    pairs.append(pair)

                    # é‡ç½®
                    current_problem = None
                    current_solution = None
                    current_explanation = None

        return pairs

    def export_results(
        self,
        pairs: List[ProblemSolutionPair],
        output_path: str,
        format: str = "json"
    ):
        """
        å¯¼å‡ºåˆ†æç»“æœ

        Args:
            pairs: é—®é¢˜-è§£æ³•å¯¹åˆ—è¡¨
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            format: è¾“å‡ºæ ¼å¼ (json, txt, md)
        """
        output_file = Path(output_path)
        output_file.parent.mkdir(parents=True, exist_ok=True)

        try:
            if format == "json":
                self._export_json(pairs, output_file)
            elif format == "txt":
                self._export_txt(pairs, output_file)
            elif format == "md":
                self._export_markdown(pairs, output_file)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„å¯¼å‡ºæ ¼å¼: {format}")

            logger.info(f"âœ… ç»“æœå·²å¯¼å‡ºåˆ°: {output_path}")

        except Exception as e:
            logger.error(f"å¯¼å‡ºå¤±è´¥: {e}")

    def _export_json(self, pairs: List[ProblemSolutionPair], output_file: Path):
        """å¯¼å‡ºä¸ºJSONæ ¼å¼"""
        data = {
            "pairs": [pair.to_dict() for pair in pairs],
            "total_count": len(pairs)
        }

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

    def _export_txt(self, pairs: List[ProblemSolutionPair], output_file: Path):
        """å¯¼å‡ºä¸ºæ–‡æœ¬æ ¼å¼"""
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write("=" * 80 + "\n")
            f.write("Logic Analysis Report: Problem-Solution Pairs\n")
            f.write("=" * 80 + "\n\n")

            for i, pair in enumerate(pairs, 1):
                f.write(f"ã€Pair {i}ã€‘\n")
                f.write(f"Confidence: {pair.confidence:.2f}\n\n")
                f.write(f"Problem (The Lock):\n{pair.problem}\n\n")
                f.write(f"Solution (The Key):\n{pair.solution}\n\n")
                f.write(f"Explanation:\n{pair.explanation}\n\n")

                if pair.evidence:
                    f.write(f"Evidence:\n{pair.evidence}\n\n")

                f.write("-" * 80 + "\n\n")

    def _export_markdown(self, pairs: List[ProblemSolutionPair], output_file: Path):
        """å¯¼å‡ºä¸ºMarkdownæ ¼å¼"""
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write("# Logic Analysis Report: Problem-Solution Pairs\n\n")

            for i, pair in enumerate(pairs, 1):
                f.write(f"## Pair {i}\n\n")
                f.write(f"**Confidence:** {pair.confidence:.2f}\n\n")

                f.write(f"### ğŸ”’ Problem (The Lock)\n\n")
                f.write(f"{pair.problem}\n\n")

                f.write(f"### ğŸ”‘ Solution (The Key)\n\n")
                f.write(f"{pair.solution}\n\n")

                f.write(f"### ğŸ’¡ Explanation\n\n")
                f.write(f"{pair.explanation}\n\n")

                if pair.evidence:
                    f.write(f"### ğŸ“ Evidence\n\n")
                    f.write(f"> {pair.evidence}\n\n")

                f.write("---\n\n")


def main():
    """æµ‹è¯•ä»£ç """
    import argparse
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )

    parser = argparse.ArgumentParser(description="Logic Analyst Agent - è®ºæ–‡é€»è¾‘åˆ†æ")
    parser.add_argument("--config", required=True, help="LLMé…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--paper", required=True, help="è®ºæ–‡æ–‡æœ¬æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--output", default="logic_analysis_results.json", help="è¾“å‡ºæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--format", choices=["json", "txt", "md"], default="json", help="è¾“å‡ºæ ¼å¼")

    args = parser.parse_args()

    try:
        # åˆå§‹åŒ–LLMå®¢æˆ·ç«¯
        config = LLMConfig.from_file(args.config)
        llm_client = LLMClient(config)

        # è¯»å–è®ºæ–‡å†…å®¹
        with open(args.paper, 'r', encoding='utf-8') as f:
            paper_content = f.read()

        # åˆ›å»ºåˆ†æagent
        agent = LogicAnalystAgent(llm_client)

        # æ‰§è¡Œåˆ†æ
        pairs = agent.analyze(paper_content)

        # å¯¼å‡ºç»“æœ
        agent.export_results(pairs, args.output, format=args.format)

        # æ‰“å°æ‘˜è¦
        print("\n" + "=" * 80)
        print(f"Logic Analysis Complete: Found {len(pairs)} Problem-Solution Pairs")
        print("=" * 80)

        for i, pair in enumerate(pairs, 1):
            print(f"\nã€Pair {i}ã€‘(Confidence: {pair.confidence:.2f})")
            print(f"Problem: {pair.problem[:100]}...")
            print(f"Solution: {pair.solution[:100]}...")

    except Exception as e:
        logger.error(f"æ‰§è¡Œå¤±è´¥: {e}")
        raise


if __name__ == "__main__":
    main()
