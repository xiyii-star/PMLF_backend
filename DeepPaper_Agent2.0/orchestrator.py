"""
DeepPaper 2.0 Orchestrator (åè°ƒå™¨)
æ•´åˆæ‰€æœ‰ç»„ä»¶ï¼Œåè°ƒè®ºæ–‡æ·±åº¦ä¿¡æ¯æå–æµç¨‹

å·¥ä½œæµç¨‹:
1. Problem: ä½¿ç”¨ LogicAnalystAgent æå–é—®é¢˜
2. Method: ä½¿ç”¨ LogicAnalystAgent æå–æ–¹æ³•
3. Limitation: ä½¿ç”¨ LimitationExtractor (ç« èŠ‚å®šä½ + å¼•ç”¨åˆ†æ)
4. Future Work: ä½¿ç”¨ FutureWorkExtractor (ç« èŠ‚å®šä½)
5. æ•´åˆç»“æœè¾“å‡ºæœ€ç»ˆæŠ¥å‘Š


"""

import json
import logging
from typing import Dict, Optional
from pathlib import Path
import sys

# æ·»åŠ å½“å‰ç›®å½•åˆ°sys.pathä»¥æ”¯æŒç›¸å¯¹å¯¼å…¥
_current_dir = Path(__file__).parent
if str(_current_dir) not in sys.path:
    sys.path.insert(0, str(_current_dir))

# å¯¼å…¥æ•°æ®ç»“æ„
from data_structures import (
    PaperDocument,
    PaperSection,
    FinalReport,
    FieldType,
    ExtractionResult
)

# å¯¼å…¥å„ä¸ªAgent
from LogicAnalystAgent import LogicAnalystAgent
from LimitationExtractor import LimitationExtractor
from FutureWorkExtractor import FutureWorkExtractor

# å¯¼å…¥LLMé…ç½®
sys.path.append(str(Path(__file__).parent.parent))
from src.llm_config import LLMClient, LLMConfig

logger = logging.getLogger(__name__)


class DeepPaper2Orchestrator:
    """
    DeepPaper 2.0 åè°ƒå™¨
    æ•´åˆæ‰€æœ‰ç»„ä»¶å®Œæˆè®ºæ–‡æ·±åº¦ä¿¡æ¯æå–
    """

    def __init__(
        self,
        llm_client: LLMClient,
        use_citation_analysis: bool = False
    ):
        """
        åˆå§‹åŒ–åè°ƒå™¨

        Args:
            llm_client: LLMå®¢æˆ·ç«¯
            use_citation_analysis: æ˜¯å¦å¯¹limitationä½¿ç”¨å¼•ç”¨åˆ†æ
        """
        self.llm_client = llm_client
        self.use_citation_analysis = use_citation_analysis

        # åˆå§‹åŒ–æ‰€æœ‰Agent
        logger.info("åˆå§‹åŒ– DeepPaper 2.0 Multi-Agent ç³»ç»Ÿ...")
        self.logic_analyst = LogicAnalystAgent(llm_client)
        self.limitation_extractor = LimitationExtractor(
            llm_client,
            use_citation_analysis=use_citation_analysis
        )
        self.future_work_extractor = FutureWorkExtractor(llm_client)

        logger.info("Agentåˆå§‹åŒ–å®Œæˆ:")
        logger.info("   - LogicAnalystAgent (é€»è¾‘åˆ†æå‘˜)")
        logger.info("   - LimitationExtractor (å±€é™æ€§æå–å™¨)")
        logger.info("   - FutureWorkExtractor (æœªæ¥å·¥ä½œæå–å™¨)")
        if use_citation_analysis:
            logger.info("   - CitationDetectiveAgent (å¼•ç”¨ä¾¦æ¢) [å·²å¯ç”¨]")

    def analyze_paper(
        self,
        paper_document: PaperDocument,
        paper_id: Optional[str] = None,
        output_dir: Optional[str] = None
    ) -> FinalReport:
        """
        åˆ†æè®ºæ–‡å¹¶è¿”å›æ·±åº¦è§£ææŠ¥å‘Š

        Args:
            paper_document: è®ºæ–‡æ–‡æ¡£
            paper_id: è®ºæ–‡IDï¼ˆç”¨äºå¼•ç”¨åˆ†æï¼Œå¯é€‰ï¼‰
            output_dir: è¾“å‡ºç›®å½•ï¼ˆå¯é€‰ï¼‰

        Returns:
            FinalReport: æœ€ç»ˆæŠ¥å‘Š
        """
        logger.info(f"\n{'=' * 80}")
        logger.info(f"ğŸš€ å¼€å§‹ DeepPaper 2.0 åˆ†æ")
        logger.info(f"{'=' * 80}")
        logger.info(f"è®ºæ–‡: {paper_document.title}")
        logger.info(f"ç« èŠ‚æ•°: {len(paper_document.sections)}")
        logger.info(f"{'=' * 80}\n")

        # æ„å»ºç”¨äºLogicAnalystAgentçš„éƒ¨åˆ†ï¼šæ ‡é¢˜ã€æ‘˜è¦ã€introduction
        paper_content = self._build_paper_content(paper_document)

        # æå–ç»“æœå­—å…¸
        extractions: Dict[FieldType, ExtractionResult] = {}

        # 1. æå– Problem å’Œ Method (ä½¿ç”¨ LogicAnalystAgent)
        logger.info(f"\n{'â”€' * 80}")
        logger.info(f"ğŸ“‹ [Step 1/2] ä½¿ç”¨ LogicAnalystAgent æå– Problem & Method")
        logger.info(f"{'â”€' * 80}")

        problem_result, method_result = self._extract_problem_and_method(
            paper_content,
            paper_document
        )

        extractions[FieldType.PROBLEM] = problem_result
        extractions[FieldType.METHOD] = method_result

        # 2. æå– Limitation (ä½¿ç”¨ LimitationExtractor)
        logger.info(f"\n{'â”€' * 80}")
        logger.info(f"ğŸ“‹ [Step 2/2] æå– Limitation & Future Work")
        logger.info(f"{'â”€' * 80}")

        limitation_result = self.limitation_extractor.extract(
            paper=paper_document,
            paper_id=paper_id
        )
        extractions[FieldType.LIMITATION] = limitation_result

        # 3. æå– Future Work (ä½¿ç”¨ FutureWorkExtractor)
        future_work_result = self.future_work_extractor.extract(
            paper=paper_document
        )
        extractions[FieldType.FUTURE_WORK] = future_work_result

        # 4. ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        logger.info(f"\n{'=' * 80}")
        logger.info(f"ğŸ“ ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š")
        logger.info(f"{'=' * 80}\n")

        report = self._build_final_report(paper_document, extractions)

        # ä¿å­˜æŠ¥å‘Š
        if output_dir:
            self._save_report(report, output_dir)

        logger.info(f"\n{'=' * 80}")
        logger.info(f"âœ… DeepPaper 2.0 åˆ†æå®Œæˆ!")
        logger.info(f"{'=' * 80}\n")

        return report

    def _build_paper_content(self, paper: PaperDocument) -> str:
        """
        æ„å»ºè®ºæ–‡å†…å®¹ï¼ˆç”¨äºLogicAnalystAgentï¼‰
        åªåŒ…å«æ ‡é¢˜ã€æ‘˜è¦å’ŒIntroductionéƒ¨åˆ†

        Args:
            paper: è®ºæ–‡æ–‡æ¡£

        Returns:
            è®ºæ–‡å†…å®¹å­—ç¬¦ä¸²ï¼ˆæ ‡é¢˜ + æ‘˜è¦ + Introductionï¼‰
        """
        content_parts = []

        # æ·»åŠ æ ‡é¢˜
        if paper.title:
            content_parts.append(f"Title: {paper.title}\n")

        # æ·»åŠ æ‘˜è¦
        if paper.abstract:
            content_parts.append(f"Abstract:\n{paper.abstract}\n")

        # åªæ·»åŠ Introductionç« èŠ‚
        for section in paper.sections:
            # åŒ¹é…Introductionç« èŠ‚ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
            if section.title.lower().strip() in ['introduction', '1. introduction', '1 introduction']:
                content_parts.append(f"\n{section.title}\n")
                content_parts.append(section.content)
                break  # åªå–ç¬¬ä¸€ä¸ªåŒ¹é…çš„Introduction

        return "\n".join(content_parts)

    def _extract_problem_and_method(
        self,
        paper_content: str,
        paper_document: PaperDocument
    ) -> tuple:
        """
        ä½¿ç”¨LogicAnalystAgentæå–Problemå’ŒMethod

        Args:
            paper_content: è®ºæ–‡å…¨æ–‡
            paper_document: è®ºæ–‡æ–‡æ¡£å¯¹è±¡

        Returns:
            (problem_result, method_result)
        """
        # æ„å»ºå…ƒæ•°æ®
        metadata = {
            "title": paper_document.title,
            "authors": paper_document.authors,
            "year": paper_document.year
        }

        # è°ƒç”¨LogicAnalystAgent
        pairs = self.logic_analyst.analyze(
            paper_content=paper_content,
            paper_metadata=metadata
        )

        # è§£æç»“æœ
        if pairs:
            # å–ç¬¬ä¸€ä¸ªæœ€æ ¸å¿ƒçš„Problem-Solution Pair
            main_pair = pairs[0]

            # æ„å»ºProblemç»“æœ
            problem_result = ExtractionResult(
                field=FieldType.PROBLEM,
                content=main_pair.problem,
                evidence=[{"text": main_pair.evidence}] if main_pair.evidence else [],
                extraction_method="logic_analyst",
                confidence=main_pair.confidence,
                iterations=1
            )

            # æ„å»ºMethodç»“æœ
            method_content = f"{main_pair.solution}\n\n**Explanation:** {main_pair.explanation}"
            method_result = ExtractionResult(
                field=FieldType.METHOD,
                content=method_content,
                evidence=[{"text": main_pair.evidence}] if main_pair.evidence else [],
                extraction_method="logic_analyst",
                confidence=main_pair.confidence,
                iterations=1
            )

            logger.info(f"  âœ… Problem: {problem_result.content[:100]}...")
            logger.info(f"  âœ… Method: {method_result.content[:100]}...")

        else:
            # é™çº§ï¼šæœªæ‰¾åˆ°
            logger.warning("  âš ï¸ LogicAnalystAgentæœªæ‰¾åˆ°Problem-Solution Pairs")
            problem_result = ExtractionResult(
                field=FieldType.PROBLEM,
                content="æœªæ‰¾åˆ°æ˜ç¡®çš„ç ”ç©¶é—®é¢˜æè¿°",
                evidence=[],
                extraction_method="logic_analyst",
                confidence=0.0,
                iterations=1
            )
            method_result = ExtractionResult(
                field=FieldType.METHOD,
                content="æœªæ‰¾åˆ°æ˜ç¡®çš„æ–¹æ³•æè¿°",
                evidence=[],
                extraction_method="logic_analyst",
                confidence=0.0,
                iterations=1
            )

        return problem_result, method_result

    def _build_final_report(
        self,
        paper: PaperDocument,
        extractions: Dict[FieldType, ExtractionResult]
    ) -> FinalReport:
        """
        æ„å»ºæœ€ç»ˆæŠ¥å‘Š

        Args:
            paper: è®ºæ–‡æ–‡æ¡£
            extractions: æå–ç»“æœå­—å…¸

        Returns:
            FinalReport
        """
        # æå–å„å­—æ®µå†…å®¹
        problem_ext = extractions.get(FieldType.PROBLEM)
        method_ext = extractions.get(FieldType.METHOD)
        limitation_ext = extractions.get(FieldType.LIMITATION)
        future_work_ext = extractions.get(FieldType.FUTURE_WORK)

        report = FinalReport(
            paper_id=paper.paper_id,
            title=paper.title,
            problem=problem_ext.content if problem_ext else "æœªæå–",
            method=method_ext.content if method_ext else "æœªæå–",
            limitation=limitation_ext.content if limitation_ext else "æœªæå–",
            future_work=future_work_ext.content if future_work_ext else "æœªæå–",
            problem_evidence=problem_ext.evidence if problem_ext else [],
            method_evidence=method_ext.evidence if method_ext else [],
            limitation_evidence=limitation_ext.evidence if limitation_ext else [],
            future_work_evidence=future_work_ext.evidence if future_work_ext else [],
            metadata={
                "authors": paper.authors,
                "year": paper.year,
                "extraction_methods": {
                    "problem": problem_ext.extraction_method if problem_ext else "unknown",
                    "method": method_ext.extraction_method if method_ext else "unknown",
                    "limitation": limitation_ext.extraction_method if limitation_ext else "unknown",
                    "future_work": future_work_ext.extraction_method if future_work_ext else "unknown"
                },
                "confidences": {
                    "problem": problem_ext.confidence if problem_ext else 0.0,
                    "method": method_ext.confidence if method_ext else 0.0,
                    "limitation": limitation_ext.confidence if limitation_ext else 0.0,
                    "future_work": future_work_ext.confidence if future_work_ext else 0.0
                }
            }
        )

        return report

    def _save_report(self, report: FinalReport, output_dir: str):
        """
        ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶

        ç”Ÿæˆä¸¤ç§æ ¼å¼:
        1. JSONæ ¼å¼(æœºå™¨å¯è¯»)
        2. Markdownæ ¼å¼(äººç±»å¯è¯»)
        """
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)

        # ç”Ÿæˆæ–‡ä»¶å
        safe_id = report.paper_id.replace('/', '_').replace(':', '_')
        json_file = output_path / f"deeppaper2_{safe_id}.json"
        md_file = output_path / f"deeppaper2_{safe_id}.md"

        # ä¿å­˜JSON
        try:
            with open(json_file, 'w', encoding='utf-8') as f:
                json.dump(report.to_dict(), f, ensure_ascii=False, indent=2)
            logger.info(f"  âœ… JSONæŠ¥å‘Šå·²ä¿å­˜: {json_file}")
        except Exception as e:
            logger.error(f"  âŒ JSONä¿å­˜å¤±è´¥: {e}")

        # ä¿å­˜Markdown
        try:
            md_content = self._generate_markdown_report(report)
            with open(md_file, 'w', encoding='utf-8') as f:
                f.write(md_content)
            logger.info(f"  âœ… MarkdownæŠ¥å‘Šå·²ä¿å­˜: {md_file}")
        except Exception as e:
            logger.error(f"  âŒ Markdownä¿å­˜å¤±è´¥: {e}")

    def _generate_markdown_report(self, report: FinalReport) -> str:
        """ç”ŸæˆMarkdownæ ¼å¼çš„æŠ¥å‘Š"""
        lines = [
            f"# {report.title}",
            "",
            "## Paper Information",
            f"- **Paper ID**: {report.paper_id}",
            f"- **Authors**: {', '.join(report.metadata.get('authors', []))}",
            f"- **Year**: {report.metadata.get('year', 'N/A')}",
            "",
            "---",
            "",
            "## Problem",
            "",
            report.problem,
            "",
            "---",
            "",
            "## Method",
            "",
            report.method,
            "",
            "---",
            "",
            "## Limitation",
            "",
            report.limitation,
            "",
            "---",
            "",
            "## Future Work",
            "",
            report.future_work,
            "",
            "---",
            "",
            "## Metadata",
            "",
            "### Extraction Methods",
            ""
        ]

        # æ·»åŠ æå–æ–¹æ³•ä¿¡æ¯
        methods = report.metadata.get('extraction_methods', {})
        for field, method in methods.items():
            lines.append(f"- **{field}**: {method}")

        lines.append("")
        lines.append("### Confidences")
        lines.append("")

        # æ·»åŠ ç½®ä¿¡åº¦ä¿¡æ¯
        confidences = report.metadata.get('confidences', {})
        for field, confidence in confidences.items():
            lines.append(f"- **{field}**: {confidence:.2f}")

        return "\n".join(lines)


def main():
    """æµ‹è¯•ä»£ç """
    import argparse
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )

    parser = argparse.ArgumentParser(description="DeepPaper 2.0 Orchestrator - è®ºæ–‡æ·±åº¦ä¿¡æ¯æå–")
    parser.add_argument("--config", required=True, help="LLMé…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--paper", required=True, help="è®ºæ–‡æ–‡æœ¬æ–‡ä»¶è·¯å¾„ï¼ˆJSONæ ¼å¼ï¼‰")
    parser.add_argument("--paper-id", help="è®ºæ–‡IDï¼ˆç”¨äºå¼•ç”¨åˆ†æï¼Œå¯é€‰ï¼‰")
    parser.add_argument("--use-citation", action="store_true", help="æ˜¯å¦å¯¹limitationä½¿ç”¨å¼•ç”¨åˆ†æ")
    parser.add_argument("--output", default="./output", help="è¾“å‡ºç›®å½•")

    args = parser.parse_args()

    try:
        # åˆå§‹åŒ–LLMå®¢æˆ·ç«¯
        config = LLMConfig.from_file(args.config)
        llm_client = LLMClient(config)

        # è¯»å–è®ºæ–‡æ–‡æ¡£
        with open(args.paper, 'r', encoding='utf-8') as f:
            paper_data = json.load(f)

        # è½¬æ¢ä¸ºPaperDocumentå¯¹è±¡
        sections = [
            PaperSection(**section) for section in paper_data.get('sections', [])
        ]
        paper = PaperDocument(
            paper_id=paper_data.get('paper_id', 'unknown'),
            title=paper_data.get('title', ''),
            abstract=paper_data.get('abstract', ''),
            authors=paper_data.get('authors', []),
            year=paper_data.get('year'),
            sections=sections,
            metadata=paper_data.get('metadata')
        )

        # åˆ›å»ºåè°ƒå™¨
        orchestrator = DeepPaper2Orchestrator(
            llm_client=llm_client,
            use_citation_analysis=args.use_citation
        )

        # æ‰§è¡Œåˆ†æ
        report = orchestrator.analyze_paper(
            paper_document=paper,
            paper_id=args.paper_id,
            output_dir=args.output
        )

        # æ‰“å°æ‘˜è¦
        print("\n" + "=" * 80)
        print("DeepPaper 2.0 Analysis Complete")
        print("=" * 80)
        print(f"\nPaper: {report.title}")
        print(f"\nProblem: {report.problem[:150]}...")
        print(f"\nMethod: {report.method[:150]}...")
        print(f"\nLimitation: {report.limitation[:150]}...")
        print(f"\nFuture Work: {report.future_work[:150]}...")
        print(f"\nâœ… å®Œæ•´æŠ¥å‘Šå·²ä¿å­˜åˆ°: {args.output}")

    except Exception as e:
        logger.error(f"æ‰§è¡Œå¤±è´¥: {e}")
        raise


if __name__ == "__main__":
    main()
